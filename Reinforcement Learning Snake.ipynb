{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab #grabbing image\n",
    "from PIL import Image\n",
    "import cv2 #opencv\n",
    "import io\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (30, 30)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "#keras imports\n",
    "%matplotlib inline \n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from collections import deque\n",
    "import random\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"game/snake.html\"\n",
    "chrome_driver_path = \"../chromedriver.exe\"\n",
    "loss_file_path = \"./objects/loss_df.csv\"\n",
    "actions_file_path = \"./objects/actions_df.csv\"\n",
    "scores_file_path = \"./objects/scores_df.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Module\n",
    "This is the main module that implements interfacing between the python and browser-javascript using selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        self._driver = webdriver.Chrome(executable_path = \"chromedriver.exe\",chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.set_window_size(400,500)\n",
    "        self._driver.get(os.path.abspath(game_url))\n",
    "        #modifying game before trainNetworkining\n",
    "#         if custom_config:\n",
    "#             self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Init.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Init.instance_.playing\")\n",
    "    def restart(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ENTER)\n",
    "        \n",
    "        time.sleep(0.25)# no actions are possible \n",
    "                        # for 0.25 sec after game starts, \n",
    "                        # skip learning at this time and make the model wait\n",
    "    def press_enter(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ENTER)\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def press_down(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_DOWN)\n",
    "    def press_left(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_LEFT)\n",
    "    def press_right(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_RIGHT)\n",
    "        \n",
    "    def get_score(self):\n",
    "#         score_array = self._driver.execute_script(\"return Init.instance_.score\")\n",
    "        score = self._driver.execute_script(\"return Init.instance_.score\")\n",
    "        return int(score)\n",
    "#     def pause(self):\n",
    "#         return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "#     def resume(self):\n",
    "#         return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent module\n",
    "This model represent the agent (Dino) which the model controls for playing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeAgent:\n",
    "    def __init__(self,game): #takes game as input for taking actions\n",
    "        self._game = game; \n",
    "        self.start(); #to start the game, we need to jump once\n",
    "        time.sleep(.5) # no action can be performed for the first time when game starts\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def up(self):\n",
    "        self._game.press_up()\n",
    "    def start(self):\n",
    "        self._game.press_enter()\n",
    "    def down(self):\n",
    "        self._game.press_down()\n",
    "    def left(self):\n",
    "        self._game.press_left()\n",
    "    def right(self):\n",
    "        self._game.press_right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game state module\n",
    "Game state helps to get the current state of the game environment as well as the agent.<br>\n",
    "Actions are performed by this model before getting a new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img() #display the processed image on screen using openCV, implemented using python coroutine \n",
    "        self._display.__next__() # initiliaze the display coroutine \n",
    "    def get_state(self,actions):\n",
    "#         actions_df.loc[len(actions_df)] = actions[1:]\n",
    "        print(actions[1:])# storing actions in a dataframe\n",
    "        score = self._game.get_score() \n",
    "        reward = 0.01*score - 0.01 # dynamic reward calculation\n",
    "        is_over = False #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.left()\n",
    "#             actions = [0,-1,-1,0,0]\n",
    "            reward = 0.1*score\n",
    "        elif actions[2] == 1:\n",
    "            self._agent.right()\n",
    "#             actions = [0,-1,-1,0,0]\n",
    "            reward = 0.1*score\n",
    "        elif actions[3] == 1:\n",
    "            self._agent.up()\n",
    "#             actions = [0,0,0,-1,-1]\n",
    "            reward = 0.1*score\n",
    "        elif actions[4] == 1:\n",
    "            self._agent.down()\n",
    "#             actions = [0,0,0,-1,-1]\n",
    "            reward = 0.1*score\n",
    "        image = grab_screen() \n",
    "        self._display.send(image) #display the image on screen\n",
    "\n",
    "        if self._agent.is_crashed():\n",
    "#             scores_df.loc[len(loss_df)] = score # log the score when game is over\n",
    "            self._game.restart()\n",
    "            if score == 0:\n",
    "                reward = 0.0\n",
    "            else:\n",
    "                reward = score\n",
    "            is_over = True\n",
    "        return image, reward, is_over #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('objects/'+ name + '.pkl', 'wb') as f: #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('objects/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def grab_screen(_driver = None):\n",
    "    screen =  np.array(ImageGrab.grab(bbox=(0,210,380,430))) #bbox = region of interset on the entire screen\n",
    "    image = process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    #game is already in grey scale canvas, canny to get only edges and reduce unwanted objects(clouds)\n",
    "    image = cv2.resize(image, (0,0), fx = 0.4, fy = 0.4) # resale image dimensions\n",
    "#     image = image[2:38,10:50] #img[y:y+h, x:x+w] #crop out the dino agent from the frame\n",
    "    image = cv2.Canny(image, threshold1 = 100, threshold2 = 200) #apply the canny edge detection\n",
    "    return  image\n",
    "def show_img(graphs = False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)        \n",
    "        imS = cv2.resize(screen, (800, 400)) \n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # g = Game()\n",
    "# # s = SnakeAgent(g)\n",
    "# # Game_sate(s,g)\n",
    "# i = grab_screen()\n",
    "# i = process_img(i)\n",
    "# i = cv2.resize(i, (800, 400)) \n",
    "# cv2.imshow('window_title', i)\n",
    "# ImageGrab.grab(bbox=(0,210,380,430))\n",
    "# m = np.array(ImageGrab.grab(bbox=(0,210,380,430)))\n",
    "# m  = cv2.resize(m, (0,0), fx = 0.4, fy = 0.4)\n",
    "# m = cv2.Canny(m, threshold1 = 100, threshold2 = 200)\n",
    "# m = cv2.resize(m, (800, 400))\n",
    "# cv2.imwrite('color_img.jpg', m)\n",
    "# cv2.imshow(\"image\", m);\n",
    "# cv2.waitKey();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize log structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns =['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns = ['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns = ['actions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_obj(INITIAL_EPSILON,\"epsilon\")\n",
    "    t = 0\n",
    "    save_obj(t,\"time\")\n",
    "    D = deque()\n",
    "    save_obj(D,\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 5 # possible actions\n",
    "GAMMA = 0.99 # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100. # timesteps to observe before training\n",
    "EXPLORE = 1000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001 # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1 # starting value of epsilon\n",
    "REPLAY_MEMORY = 50 # number of previous transitions to remember\n",
    "BATCH = 32 # size of minibatch\n",
    "FRAME_PER_ACTION = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 152,88\n",
    "img_channels = 4 #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4), padding='same',input_shape=(img_cols,img_rows,img_channels)))  #20*40*4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we build the model\n",
      "We finish building the model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_106 (Conv2D)          (None, 22, 38, 32)        8224      \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 22, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 11, 19, 64)        32832     \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 11, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 11, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 11, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 13376)             0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               6849024   \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 6,929,573\n",
      "Trainable params: 6,929,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "buildmodel().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate wherther the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "def trainNetwork(model,game_state,observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = deque() #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] = 1 #0 =>do nothing, 1=>left, 2=>right, 3=>up, 4=>down\n",
    "    \n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing) # get next step after performing the action\n",
    "#     acts = [0,-1,-1,0,0]\n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2) # stack 4 images to create placeholder input\n",
    "    \n",
    "\n",
    "    \n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "    \n",
    "    initial_state = s_t \n",
    "\n",
    "    if observe :\n",
    "        OBSERVE = 999999999    #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print (\"Now we load weight\")\n",
    "#         model.load_weights(\"model_final.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "        print (\"Weight load successfully\")    \n",
    "    else:                       #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = INITIAL_EPSILON\n",
    "#         model.load_weights(\"model_final.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse',optimizer=adam)\n",
    "    t=0\n",
    "#     t = load_obj(\"time\") # resume from the previous time step stored in file system\n",
    "    while (True): #endless running\n",
    "        \n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0 #reward at 4\n",
    "        a_t = np.zeros([ACTIONS]) # action at t\n",
    "        \n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0: #parameter to skip frames for actions\n",
    "            if  random.random() <= epsilon: #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "#                 while True:\n",
    "#                     action_index = random.randrange(ACTIONS)\n",
    "#                     if a_t[action_index] != -1\n",
    "#                         a_t[action_index] = 1\n",
    "#                         break\n",
    "            else: # predict the output\n",
    "                q = model.predict(s_t)       #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)         # chosing index with maximum q value\n",
    "                action_index = max_Q \n",
    "                a_t[action_index] = 1        # 0=> do nothing, 1=> jump\n",
    "                \n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE \n",
    "\n",
    "        #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('reward: {}'.format(r_t))\n",
    "        print('loop took {} seconds'.format(time.time()-last_time)) # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1) #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3) # append the new image to input stack and remove the first one\n",
    "        \n",
    "        \n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE: \n",
    "            \n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))   #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))                         #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]    # 4D stack of images\n",
    "                action_t = minibatch[i][1]   #This is action index\n",
    "                reward_t = minibatch[i][2]   #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]   #next state\n",
    "                terminal = minibatch[i][4]   #wheather the agent died or survided due the action\n",
    "                \n",
    "\n",
    "                inputs[i:i + 1] = state_t    \n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)      #predict q values for next step\n",
    "                \n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "        else:\n",
    "            # artificial time delay as training done with this delay\n",
    "            time.sleep(0.12)\n",
    "        s_t = initial_state if terminal else s_t1 #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "        \n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0 and False:\n",
    "            print(\"Now we save model\")\n",
    "            \n",
    "            model.save_weights(\"model_final.h5\", overwrite=True)\n",
    "            save_obj(D,\"D\") #saving episodes\n",
    "            save_obj(t,\"time\") #caching time steps\n",
    "            save_obj(epsilon,\"epsilon\") #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects/loss_df.csv\",index=False)\n",
    "            scores_df.to_csv(\"./objects/scores_df.csv\",index=False)\n",
    "            actions_df.to_csv(\"./objects/actions_df.csv\",index=False)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state,             \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t,             \"/ Q_MAX \" , np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playGame(observe=False):\n",
    "    game = Game()\n",
    "    dino = SnakeAgent(game)\n",
    "    game_state = Game_sate(dino,game)\n",
    "    model = buildmodel()\n",
    "    try:\n",
    "        trainNetwork(model,game_state)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we build the model\n",
      "We finish building the model\n",
      "[0. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 3.2390940189361572 seconds\n",
      "TIMESTEP 1 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2630763053894043 seconds\n",
      "TIMESTEP 2 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18396711349487305 seconds\n",
      "TIMESTEP 3 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.21504998207092285 seconds\n",
      "TIMESTEP 4 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23902153968811035 seconds\n",
      "TIMESTEP 5 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.17717695236206055 seconds\n",
      "TIMESTEP 6 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22217893600463867 seconds\n",
      "TIMESTEP 7 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.166182279586792 seconds\n",
      "TIMESTEP 8 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.22417068481445312 seconds\n",
      "TIMESTEP 9 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18283462524414062 seconds\n",
      "TIMESTEP 10 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18226242065429688 seconds\n",
      "TIMESTEP 11 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18423199653625488 seconds\n",
      "TIMESTEP 12 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18153834342956543 seconds\n",
      "TIMESTEP 13 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18656659126281738 seconds\n",
      "TIMESTEP 14 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2365725040435791 seconds\n",
      "TIMESTEP 15 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.17784762382507324 seconds\n",
      "TIMESTEP 16 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.5429925918579102 seconds\n",
      "TIMESTEP 17 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1695857048034668 seconds\n",
      "TIMESTEP 18 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.186751127243042 seconds\n",
      "TIMESTEP 19 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.17811083793640137 seconds\n",
      "TIMESTEP 20 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.19480681419372559 seconds\n",
      "TIMESTEP 21 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20962119102478027 seconds\n",
      "TIMESTEP 22 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1791212558746338 seconds\n",
      "TIMESTEP 23 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18799543380737305 seconds\n",
      "TIMESTEP 24 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "----------Random Action----------\n",
      "[0. 0. 1. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.21246337890625 seconds\n",
      "TIMESTEP 25 / STATE observe / EPSILON 0.1 / ACTION 3 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22545313835144043 seconds\n",
      "TIMESTEP 26 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18411755561828613 seconds\n",
      "TIMESTEP 27 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22216272354125977 seconds\n",
      "TIMESTEP 28 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.19611501693725586 seconds\n",
      "TIMESTEP 29 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.19097232818603516 seconds\n",
      "TIMESTEP 30 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18885159492492676 seconds\n",
      "TIMESTEP 31 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20647716522216797 seconds\n",
      "TIMESTEP 32 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.5236668586730957 seconds\n",
      "TIMESTEP 33 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.17905807495117188 seconds\n",
      "TIMESTEP 34 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2111055850982666 seconds\n",
      "TIMESTEP 35 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20591473579406738 seconds\n",
      "TIMESTEP 36 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18254828453063965 seconds\n",
      "TIMESTEP 37 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18030905723571777 seconds\n",
      "TIMESTEP 38 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.16803574562072754 seconds\n",
      "TIMESTEP 39 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1858382225036621 seconds\n",
      "TIMESTEP 40 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.21857810020446777 seconds\n",
      "TIMESTEP 41 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.176743745803833 seconds\n",
      "TIMESTEP 42 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.19503211975097656 seconds\n",
      "TIMESTEP 43 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1776587963104248 seconds\n",
      "TIMESTEP 44 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1796114444732666 seconds\n",
      "TIMESTEP 45 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2575211524963379 seconds\n",
      "TIMESTEP 46 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24879837036132812 seconds\n",
      "TIMESTEP 47 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.6167857646942139 seconds\n",
      "TIMESTEP 48 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.3669092655181885 seconds\n",
      "TIMESTEP 49 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.21771907806396484 seconds\n",
      "TIMESTEP 50 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24649310111999512 seconds\n",
      "TIMESTEP 51 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24172687530517578 seconds\n",
      "TIMESTEP 52 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.21774601936340332 seconds\n",
      "TIMESTEP 53 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -0.01\n",
      "loop took 0.24536371231079102 seconds\n",
      "TIMESTEP 54 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.25061964988708496 seconds\n",
      "TIMESTEP 55 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1999671459197998 seconds\n",
      "TIMESTEP 56 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.3197824954986572 seconds\n",
      "TIMESTEP 57 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24071216583251953 seconds\n",
      "TIMESTEP 58 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24592089653015137 seconds\n",
      "TIMESTEP 59 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24397587776184082 seconds\n",
      "TIMESTEP 60 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24328327178955078 seconds\n",
      "TIMESTEP 61 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.5490326881408691 seconds\n",
      "TIMESTEP 62 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22804498672485352 seconds\n",
      "TIMESTEP 63 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24245285987854004 seconds\n",
      "TIMESTEP 64 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.3240482807159424 seconds\n",
      "TIMESTEP 65 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24088406562805176 seconds\n",
      "TIMESTEP 66 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23418235778808594 seconds\n",
      "TIMESTEP 67 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2441871166229248 seconds\n",
      "TIMESTEP 68 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23366189002990723 seconds\n",
      "TIMESTEP 69 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2323625087738037 seconds\n",
      "TIMESTEP 70 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22867512702941895 seconds\n",
      "TIMESTEP 71 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24562835693359375 seconds\n",
      "TIMESTEP 72 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.3487396240234375 seconds\n",
      "TIMESTEP 73 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.254758358001709 seconds\n",
      "TIMESTEP 74 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18712139129638672 seconds\n",
      "TIMESTEP 75 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23131465911865234 seconds\n",
      "TIMESTEP 76 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2188122272491455 seconds\n",
      "TIMESTEP 77 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.4746742248535156 seconds\n",
      "TIMESTEP 78 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20635628700256348 seconds\n",
      "TIMESTEP 79 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.28938865661621094 seconds\n",
      "TIMESTEP 80 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.26628708839416504 seconds\n",
      "TIMESTEP 81 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.25339674949645996 seconds\n",
      "TIMESTEP 82 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23795652389526367 seconds\n",
      "TIMESTEP 83 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.260178804397583 seconds\n",
      "TIMESTEP 84 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.22967028617858887 seconds\n",
      "TIMESTEP 85 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.210313081741333 seconds\n",
      "TIMESTEP 86 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23500990867614746 seconds\n",
      "TIMESTEP 87 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.19715547561645508 seconds\n",
      "TIMESTEP 88 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.30420398712158203 seconds\n",
      "TIMESTEP 89 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2001032829284668 seconds\n",
      "TIMESTEP 90 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.2059171199798584 seconds\n",
      "TIMESTEP 91 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23845601081848145 seconds\n",
      "TIMESTEP 92 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.18933677673339844 seconds\n",
      "TIMESTEP 93 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.1976015567779541 seconds\n",
      "TIMESTEP 94 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20009136199951172 seconds\n",
      "TIMESTEP 95 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.20107197761535645 seconds\n",
      "TIMESTEP 96 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.24193668365478516 seconds\n",
      "TIMESTEP 97 / STATE observe / EPSILON 0.1 / ACTION 4 / REWARD 0.0 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23648691177368164 seconds\n",
      "TIMESTEP 98 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.27075815200805664 seconds\n",
      "TIMESTEP 99 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.23531723022460938 seconds\n",
      "TIMESTEP 100 / STATE observe / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.24526429176330566 seconds\n",
      "TIMESTEP 101 / STATE explore / EPSILON 0.1 / ACTION 0 / REWARD -0.01 / Q_MAX  0 / Loss  0\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.6130218505859375 seconds\n",
      "TIMESTEP 102 / STATE explore / EPSILON 0.0999001 / ACTION 0 / REWARD 0.0 / Q_MAX  13.893075 / Loss  12.986401557922363\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 11.741235494613647 seconds\n",
      "TIMESTEP 103 / STATE explore / EPSILON 0.0998002 / ACTION 0 / REWARD 0.0 / Q_MAX  71.46521 / Loss  102.37059020996094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7885417938232422 seconds\n",
      "TIMESTEP 104 / STATE explore / EPSILON 0.0997003 / ACTION 0 / REWARD -0.01 / Q_MAX  83.73774 / Loss  80.37928009033203\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.8031575679779053 seconds\n",
      "TIMESTEP 105 / STATE explore / EPSILON 0.0996004 / ACTION 4 / REWARD 0.0 / Q_MAX  80.70902 / Loss  100.50352478027344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6902868747711182 seconds\n",
      "TIMESTEP 106 / STATE explore / EPSILON 0.0995005 / ACTION 0 / REWARD -0.01 / Q_MAX  95.69023 / Loss  248.99395751953125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6814444065093994 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 107 / STATE explore / EPSILON 0.0994006 / ACTION 0 / REWARD -0.01 / Q_MAX  110.135345 / Loss  213.67239379882812\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.754805326461792 seconds\n",
      "TIMESTEP 108 / STATE explore / EPSILON 0.0993007 / ACTION 0 / REWARD -0.01 / Q_MAX  127.94391 / Loss  96.79328918457031\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1099917888641357 seconds\n",
      "TIMESTEP 109 / STATE explore / EPSILON 0.0992008 / ACTION 0 / REWARD 0.0 / Q_MAX  138.44994 / Loss  390.1247253417969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.3166999816894531 seconds\n",
      "TIMESTEP 110 / STATE explore / EPSILON 0.0991009 / ACTION 0 / REWARD -0.01 / Q_MAX  151.07494 / Loss  335.8787841796875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7050845623016357 seconds\n",
      "TIMESTEP 111 / STATE explore / EPSILON 0.099001 / ACTION 0 / REWARD -0.01 / Q_MAX  143.57977 / Loss  334.96875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6941468715667725 seconds\n",
      "TIMESTEP 112 / STATE explore / EPSILON 0.0989011 / ACTION 0 / REWARD -0.01 / Q_MAX  146.55598 / Loss  219.42318725585938\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7018392086029053 seconds\n",
      "TIMESTEP 113 / STATE explore / EPSILON 0.0988012 / ACTION 4 / REWARD 0.0 / Q_MAX  158.60571 / Loss  280.572998046875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7018742561340332 seconds\n",
      "TIMESTEP 114 / STATE explore / EPSILON 0.0987013 / ACTION 0 / REWARD -0.01 / Q_MAX  130.49292 / Loss  182.8854217529297\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6652331352233887 seconds\n",
      "TIMESTEP 115 / STATE explore / EPSILON 0.0986014 / ACTION 0 / REWARD -0.01 / Q_MAX  133.72456 / Loss  183.99453735351562\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7159435749053955 seconds\n",
      "TIMESTEP 116 / STATE explore / EPSILON 0.0985015 / ACTION 0 / REWARD -0.01 / Q_MAX  137.62547 / Loss  211.74346923828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6797633171081543 seconds\n",
      "TIMESTEP 117 / STATE explore / EPSILON 0.0984016 / ACTION 0 / REWARD -0.01 / Q_MAX  139.15996 / Loss  182.046630859375\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.012603998184204 seconds\n",
      "TIMESTEP 118 / STATE explore / EPSILON 0.0983017 / ACTION 0 / REWARD 0.0 / Q_MAX  139.60544 / Loss  260.4753723144531\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8095269203186035 seconds\n",
      "TIMESTEP 119 / STATE explore / EPSILON 0.0982018 / ACTION 0 / REWARD -0.01 / Q_MAX  153.39748 / Loss  382.4621887207031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7710976600646973 seconds\n",
      "TIMESTEP 120 / STATE explore / EPSILON 0.0981019 / ACTION 0 / REWARD -0.01 / Q_MAX  137.95384 / Loss  414.63519287109375\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.8580043315887451 seconds\n",
      "TIMESTEP 121 / STATE explore / EPSILON 0.098002 / ACTION 4 / REWARD 0.0 / Q_MAX  137.17604 / Loss  148.47332763671875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8699691295623779 seconds\n",
      "TIMESTEP 122 / STATE explore / EPSILON 0.0979021 / ACTION 0 / REWARD -0.01 / Q_MAX  138.23709 / Loss  207.58306884765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7488644123077393 seconds\n",
      "TIMESTEP 123 / STATE explore / EPSILON 0.0978022 / ACTION 0 / REWARD -0.01 / Q_MAX  131.77768 / Loss  366.423583984375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7513155937194824 seconds\n",
      "TIMESTEP 124 / STATE explore / EPSILON 0.0977023 / ACTION 0 / REWARD -0.01 / Q_MAX  143.8218 / Loss  127.33175659179688\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.0035960674285889 seconds\n",
      "TIMESTEP 125 / STATE explore / EPSILON 0.0976024 / ACTION 0 / REWARD 0.0 / Q_MAX  141.9307 / Loss  162.4523468017578\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0218207836151123 seconds\n",
      "TIMESTEP 126 / STATE explore / EPSILON 0.0975025 / ACTION 0 / REWARD -0.01 / Q_MAX  128.29628 / Loss  265.3460693359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.699324369430542 seconds\n",
      "TIMESTEP 127 / STATE explore / EPSILON 0.0974026 / ACTION 0 / REWARD -0.01 / Q_MAX  127.00061 / Loss  251.7186279296875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7080028057098389 seconds\n",
      "TIMESTEP 128 / STATE explore / EPSILON 0.0973027 / ACTION 0 / REWARD -0.01 / Q_MAX  120.44262 / Loss  176.86102294921875\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7982325553894043 seconds\n",
      "TIMESTEP 129 / STATE explore / EPSILON 0.0972028 / ACTION 4 / REWARD 0.0 / Q_MAX  123.09592 / Loss  190.6365203857422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7279262542724609 seconds\n",
      "TIMESTEP 130 / STATE explore / EPSILON 0.0971029 / ACTION 0 / REWARD -0.01 / Q_MAX  120.533676 / Loss  248.48851013183594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7071177959442139 seconds\n",
      "TIMESTEP 131 / STATE explore / EPSILON 0.097003 / ACTION 0 / REWARD -0.01 / Q_MAX  119.11479 / Loss  187.21092224121094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0868453979492188 seconds\n",
      "TIMESTEP 132 / STATE explore / EPSILON 0.0969031 / ACTION 0 / REWARD -0.01 / Q_MAX  123.88409 / Loss  164.91146850585938\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2768311500549316 seconds\n",
      "TIMESTEP 133 / STATE explore / EPSILON 0.0968032 / ACTION 0 / REWARD 0.0 / Q_MAX  113.59654 / Loss  188.17672729492188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0663554668426514 seconds\n",
      "TIMESTEP 134 / STATE explore / EPSILON 0.0967033 / ACTION 0 / REWARD -0.01 / Q_MAX  109.66014 / Loss  111.6676254272461\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8142602443695068 seconds\n",
      "TIMESTEP 135 / STATE explore / EPSILON 0.0966034 / ACTION 0 / REWARD -0.01 / Q_MAX  107.57918 / Loss  161.28192138671875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7357058525085449 seconds\n",
      "TIMESTEP 136 / STATE explore / EPSILON 0.0965035 / ACTION 0 / REWARD -0.01 / Q_MAX  113.65049 / Loss  115.66606140136719\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.8685097694396973 seconds\n",
      "TIMESTEP 137 / STATE explore / EPSILON 0.0964036 / ACTION 4 / REWARD 0.0 / Q_MAX  110.48985 / Loss  127.52074432373047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7955837249755859 seconds\n",
      "TIMESTEP 138 / STATE explore / EPSILON 0.0963037 / ACTION 0 / REWARD -0.01 / Q_MAX  110.04561 / Loss  166.89935302734375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7458748817443848 seconds\n",
      "TIMESTEP 139 / STATE explore / EPSILON 0.0962038 / ACTION 0 / REWARD -0.01 / Q_MAX  102.25984 / Loss  152.97640991210938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8490381240844727 seconds\n",
      "TIMESTEP 140 / STATE explore / EPSILON 0.0961039 / ACTION 0 / REWARD -0.01 / Q_MAX  97.616165 / Loss  130.77301025390625\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3316969871520996 seconds\n",
      "TIMESTEP 141 / STATE explore / EPSILON 0.096004 / ACTION 0 / REWARD 0.0 / Q_MAX  98.32108 / Loss  133.75494384765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.061654806137085 seconds\n",
      "TIMESTEP 142 / STATE explore / EPSILON 0.0959041 / ACTION 0 / REWARD -0.01 / Q_MAX  100.1739 / Loss  168.12362670898438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8672711849212646 seconds\n",
      "TIMESTEP 143 / STATE explore / EPSILON 0.0958042 / ACTION 0 / REWARD -0.01 / Q_MAX  104.02566 / Loss  118.89083099365234\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9373469352722168 seconds\n",
      "TIMESTEP 144 / STATE explore / EPSILON 0.0957043 / ACTION 0 / REWARD -0.01 / Q_MAX  110.60104 / Loss  150.54782104492188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1614763736724854 seconds\n",
      "TIMESTEP 145 / STATE explore / EPSILON 0.0956044 / ACTION 0 / REWARD -0.01 / Q_MAX  116.806496 / Loss  129.20187377929688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1325724124908447 seconds\n",
      "TIMESTEP 146 / STATE explore / EPSILON 0.0955045 / ACTION 0 / REWARD -0.01 / Q_MAX  96.15608 / Loss  133.61685180664062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9649155139923096 seconds\n",
      "TIMESTEP 147 / STATE explore / EPSILON 0.0954046 / ACTION 0 / REWARD -0.01 / Q_MAX  107.368965 / Loss  126.702392578125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8506796360015869 seconds\n",
      "TIMESTEP 148 / STATE explore / EPSILON 0.0953047 / ACTION 0 / REWARD -0.01 / Q_MAX  147.95155 / Loss  139.42335510253906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8429744243621826 seconds\n",
      "TIMESTEP 149 / STATE explore / EPSILON 0.0952048 / ACTION 0 / REWARD -0.01 / Q_MAX  110.735115 / Loss  111.95089721679688\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1356146335601807 seconds\n",
      "TIMESTEP 150 / STATE explore / EPSILON 0.0951049 / ACTION 0 / REWARD 0.0 / Q_MAX  118.6532 / Loss  177.6361846923828\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.983642578125 seconds\n",
      "TIMESTEP 151 / STATE explore / EPSILON 0.095005 / ACTION 0 / REWARD -0.01 / Q_MAX  116.495514 / Loss  145.04867553710938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9347472190856934 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 152 / STATE explore / EPSILON 0.0949051 / ACTION 0 / REWARD -0.01 / Q_MAX  144.40791 / Loss  187.00485229492188\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.1160845756530762 seconds\n",
      "TIMESTEP 153 / STATE explore / EPSILON 0.0948052 / ACTION 4 / REWARD 0.0 / Q_MAX  156.53279 / Loss  144.64222717285156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9392538070678711 seconds\n",
      "TIMESTEP 154 / STATE explore / EPSILON 0.0947053 / ACTION 0 / REWARD -0.01 / Q_MAX  128.01764 / Loss  197.25064086914062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0706021785736084 seconds\n",
      "TIMESTEP 155 / STATE explore / EPSILON 0.0946054 / ACTION 0 / REWARD -0.01 / Q_MAX  123.823975 / Loss  150.58839416503906\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3297865390777588 seconds\n",
      "TIMESTEP 156 / STATE explore / EPSILON 0.0945055 / ACTION 0 / REWARD 0.0 / Q_MAX  139.88803 / Loss  232.56521606445312\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1282250881195068 seconds\n",
      "TIMESTEP 157 / STATE explore / EPSILON 0.0944056 / ACTION 0 / REWARD -0.01 / Q_MAX  168.17656 / Loss  218.28573608398438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.160658359527588 seconds\n",
      "TIMESTEP 158 / STATE explore / EPSILON 0.0943057 / ACTION 0 / REWARD -0.01 / Q_MAX  163.59402 / Loss  171.24488830566406\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0027658939361572 seconds\n",
      "TIMESTEP 159 / STATE explore / EPSILON 0.0942058 / ACTION 0 / REWARD -0.01 / Q_MAX  153.35826 / Loss  187.59115600585938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9749226570129395 seconds\n",
      "TIMESTEP 160 / STATE explore / EPSILON 0.0941059 / ACTION 0 / REWARD -0.01 / Q_MAX  161.91237 / Loss  257.6156005859375\n",
      "----------Random Action----------\n",
      "[0. 1. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1950948238372803 seconds\n",
      "TIMESTEP 161 / STATE explore / EPSILON 0.094006 / ACTION 2 / REWARD 0.0 / Q_MAX  154.42123 / Loss  430.01812744140625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.158254861831665 seconds\n",
      "TIMESTEP 162 / STATE explore / EPSILON 0.0939061 / ACTION 0 / REWARD -0.01 / Q_MAX  175.51086 / Loss  336.97808837890625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1044721603393555 seconds\n",
      "TIMESTEP 163 / STATE explore / EPSILON 0.0938062 / ACTION 0 / REWARD -0.01 / Q_MAX  152.81042 / Loss  336.29547119140625\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3428103923797607 seconds\n",
      "TIMESTEP 164 / STATE explore / EPSILON 0.0937063 / ACTION 0 / REWARD 0.0 / Q_MAX  153.11507 / Loss  370.7809143066406\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.071831464767456 seconds\n",
      "TIMESTEP 165 / STATE explore / EPSILON 0.0936064 / ACTION 0 / REWARD -0.01 / Q_MAX  162.82948 / Loss  286.34454345703125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.977123498916626 seconds\n",
      "TIMESTEP 166 / STATE explore / EPSILON 0.0935065 / ACTION 0 / REWARD -0.01 / Q_MAX  168.10597 / Loss  220.87339782714844\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9341597557067871 seconds\n",
      "TIMESTEP 167 / STATE explore / EPSILON 0.0934066 / ACTION 0 / REWARD -0.01 / Q_MAX  201.71643 / Loss  265.12786865234375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1013870239257812 seconds\n",
      "TIMESTEP 168 / STATE explore / EPSILON 0.0933067 / ACTION 0 / REWARD -0.01 / Q_MAX  180.45413 / Loss  303.31829833984375\n",
      "----------Random Action----------\n",
      "[1. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.138976812362671 seconds\n",
      "TIMESTEP 169 / STATE explore / EPSILON 0.0932068 / ACTION 1 / REWARD 0.0 / Q_MAX  159.16263 / Loss  410.13641357421875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0086596012115479 seconds\n",
      "TIMESTEP 170 / STATE explore / EPSILON 0.0931069 / ACTION 0 / REWARD -0.01 / Q_MAX  184.96524 / Loss  183.06884765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0785481929779053 seconds\n",
      "TIMESTEP 171 / STATE explore / EPSILON 0.093007 / ACTION 0 / REWARD -0.01 / Q_MAX  149.36975 / Loss  398.0894470214844\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.069869041442871 seconds\n",
      "TIMESTEP 172 / STATE explore / EPSILON 0.0929071 / ACTION 0 / REWARD -0.01 / Q_MAX  170.86984 / Loss  203.9878692626953\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3431141376495361 seconds\n",
      "TIMESTEP 173 / STATE explore / EPSILON 0.0928072 / ACTION 0 / REWARD 0.0 / Q_MAX  172.76071 / Loss  535.5724487304688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0450878143310547 seconds\n",
      "TIMESTEP 174 / STATE explore / EPSILON 0.0927073 / ACTION 0 / REWARD -0.01 / Q_MAX  163.759 / Loss  294.6780090332031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0136973857879639 seconds\n",
      "TIMESTEP 175 / STATE explore / EPSILON 0.0926074 / ACTION 0 / REWARD -0.01 / Q_MAX  148.37068 / Loss  223.311767578125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9752204418182373 seconds\n",
      "TIMESTEP 176 / STATE explore / EPSILON 0.0925075 / ACTION 0 / REWARD -0.01 / Q_MAX  140.00514 / Loss  177.9187469482422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0099833011627197 seconds\n",
      "TIMESTEP 177 / STATE explore / EPSILON 0.0924076 / ACTION 0 / REWARD -0.01 / Q_MAX  206.92224 / Loss  237.62911987304688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.953038215637207 seconds\n",
      "TIMESTEP 178 / STATE explore / EPSILON 0.0923077 / ACTION 0 / REWARD -0.01 / Q_MAX  170.01718 / Loss  248.48358154296875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0406689643859863 seconds\n",
      "TIMESTEP 179 / STATE explore / EPSILON 0.0922078 / ACTION 0 / REWARD -0.01 / Q_MAX  156.96814 / Loss  174.0116729736328\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0040111541748047 seconds\n",
      "TIMESTEP 180 / STATE explore / EPSILON 0.0921079 / ACTION 0 / REWARD -0.01 / Q_MAX  164.78459 / Loss  179.7757110595703\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9806997776031494 seconds\n",
      "TIMESTEP 181 / STATE explore / EPSILON 0.092008 / ACTION 0 / REWARD -0.01 / Q_MAX  149.47794 / Loss  241.40713500976562\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.310455083847046 seconds\n",
      "TIMESTEP 182 / STATE explore / EPSILON 0.0919081 / ACTION 0 / REWARD 0.0 / Q_MAX  158.78531 / Loss  365.27008056640625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0683386325836182 seconds\n",
      "TIMESTEP 183 / STATE explore / EPSILON 0.0918082 / ACTION 0 / REWARD -0.01 / Q_MAX  218.22478 / Loss  143.09652709960938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9347147941589355 seconds\n",
      "TIMESTEP 184 / STATE explore / EPSILON 0.0917083 / ACTION 0 / REWARD -0.01 / Q_MAX  198.49998 / Loss  254.14756774902344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9855327606201172 seconds\n",
      "TIMESTEP 185 / STATE explore / EPSILON 0.0916084 / ACTION 0 / REWARD -0.01 / Q_MAX  153.66765 / Loss  275.1971740722656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9595043659210205 seconds\n",
      "TIMESTEP 186 / STATE explore / EPSILON 0.0915085 / ACTION 0 / REWARD -0.01 / Q_MAX  137.28078 / Loss  325.86846923828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9387178421020508 seconds\n",
      "TIMESTEP 187 / STATE explore / EPSILON 0.0914086 / ACTION 0 / REWARD -0.01 / Q_MAX  148.4654 / Loss  313.3893737792969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9520266056060791 seconds\n",
      "TIMESTEP 188 / STATE explore / EPSILON 0.0913087 / ACTION 0 / REWARD -0.01 / Q_MAX  252.18005 / Loss  298.42315673828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9496886730194092 seconds\n",
      "TIMESTEP 189 / STATE explore / EPSILON 0.0912088 / ACTION 0 / REWARD -0.01 / Q_MAX  124.85191 / Loss  283.5280456542969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9553816318511963 seconds\n",
      "TIMESTEP 190 / STATE explore / EPSILON 0.0911089 / ACTION 0 / REWARD -0.01 / Q_MAX  141.82097 / Loss  240.44869995117188\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2775306701660156 seconds\n",
      "TIMESTEP 191 / STATE explore / EPSILON 0.091009 / ACTION 0 / REWARD 0.0 / Q_MAX  123.52952 / Loss  360.73162841796875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1749787330627441 seconds\n",
      "TIMESTEP 192 / STATE explore / EPSILON 0.0909091 / ACTION 0 / REWARD -0.01 / Q_MAX  216.6503 / Loss  136.2215576171875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9768290519714355 seconds\n",
      "TIMESTEP 193 / STATE explore / EPSILON 0.0908092 / ACTION 0 / REWARD -0.01 / Q_MAX  131.47069 / Loss  267.16943359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9490001201629639 seconds\n",
      "TIMESTEP 194 / STATE explore / EPSILON 0.0907093 / ACTION 0 / REWARD -0.01 / Q_MAX  126.475746 / Loss  308.9706726074219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9020302295684814 seconds\n",
      "TIMESTEP 195 / STATE explore / EPSILON 0.0906094 / ACTION 0 / REWARD -0.01 / Q_MAX  112.09548 / Loss  168.23126220703125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0128519535064697 seconds\n",
      "TIMESTEP 196 / STATE explore / EPSILON 0.0905095 / ACTION 0 / REWARD -0.01 / Q_MAX  108.212265 / Loss  138.9388885498047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0870938301086426 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 197 / STATE explore / EPSILON 0.0904096 / ACTION 0 / REWARD -0.01 / Q_MAX  148.1146 / Loss  223.09371948242188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0951707363128662 seconds\n",
      "TIMESTEP 198 / STATE explore / EPSILON 0.0903097 / ACTION 0 / REWARD -0.01 / Q_MAX  199.03618 / Loss  259.67315673828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9776930809020996 seconds\n",
      "TIMESTEP 199 / STATE explore / EPSILON 0.0902098 / ACTION 0 / REWARD -0.01 / Q_MAX  121.75971 / Loss  201.74740600585938\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2654659748077393 seconds\n",
      "TIMESTEP 200 / STATE explore / EPSILON 0.0901099 / ACTION 0 / REWARD 0.0 / Q_MAX  116.63614 / Loss  197.43980407714844\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0644283294677734 seconds\n",
      "TIMESTEP 201 / STATE explore / EPSILON 0.09001 / ACTION 4 / REWARD 0.0 / Q_MAX  119.37728 / Loss  168.5548095703125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9396815299987793 seconds\n",
      "TIMESTEP 202 / STATE explore / EPSILON 0.0899101 / ACTION 0 / REWARD -0.01 / Q_MAX  102.90595 / Loss  134.12351989746094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9328999519348145 seconds\n",
      "TIMESTEP 203 / STATE explore / EPSILON 0.0898102 / ACTION 0 / REWARD -0.01 / Q_MAX  111.73521 / Loss  146.33973693847656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9443280696868896 seconds\n",
      "TIMESTEP 204 / STATE explore / EPSILON 0.0897103 / ACTION 0 / REWARD -0.01 / Q_MAX  116.06413 / Loss  135.6890411376953\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.24668550491333 seconds\n",
      "TIMESTEP 205 / STATE explore / EPSILON 0.0896104 / ACTION 0 / REWARD 0.0 / Q_MAX  104.77736 / Loss  139.2920684814453\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0693755149841309 seconds\n",
      "TIMESTEP 206 / STATE explore / EPSILON 0.0895105 / ACTION 0 / REWARD -0.01 / Q_MAX  110.32829 / Loss  159.29270935058594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9352717399597168 seconds\n",
      "TIMESTEP 207 / STATE explore / EPSILON 0.0894106 / ACTION 0 / REWARD -0.01 / Q_MAX  118.217 / Loss  130.9761505126953\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9707705974578857 seconds\n",
      "TIMESTEP 208 / STATE explore / EPSILON 0.0893107 / ACTION 0 / REWARD -0.01 / Q_MAX  112.36094 / Loss  82.60569763183594\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9931292533874512 seconds\n",
      "TIMESTEP 209 / STATE explore / EPSILON 0.0892108 / ACTION 4 / REWARD 0.0 / Q_MAX  118.657 / Loss  73.25753784179688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9548609256744385 seconds\n",
      "TIMESTEP 210 / STATE explore / EPSILON 0.0891109 / ACTION 0 / REWARD -0.01 / Q_MAX  116.55416 / Loss  113.18798828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9510443210601807 seconds\n",
      "TIMESTEP 211 / STATE explore / EPSILON 0.089011 / ACTION 0 / REWARD -0.01 / Q_MAX  104.7571 / Loss  113.27057647705078\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.949120044708252 seconds\n",
      "TIMESTEP 212 / STATE explore / EPSILON 0.0889111 / ACTION 0 / REWARD -0.01 / Q_MAX  100.02005 / Loss  120.94571685791016\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2499713897705078 seconds\n",
      "TIMESTEP 213 / STATE explore / EPSILON 0.0888112 / ACTION 0 / REWARD 0.0 / Q_MAX  123.71789 / Loss  110.31045532226562\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1313238143920898 seconds\n",
      "TIMESTEP 214 / STATE explore / EPSILON 0.0887113 / ACTION 0 / REWARD -0.01 / Q_MAX  118.43314 / Loss  172.7191619873047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9675571918487549 seconds\n",
      "TIMESTEP 215 / STATE explore / EPSILON 0.0886114 / ACTION 0 / REWARD -0.01 / Q_MAX  124.17393 / Loss  169.2845916748047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9655325412750244 seconds\n",
      "TIMESTEP 216 / STATE explore / EPSILON 0.0885115 / ACTION 0 / REWARD -0.01 / Q_MAX  124.74828 / Loss  98.48297119140625\n",
      "----------Random Action----------\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9679913520812988 seconds\n",
      "TIMESTEP 217 / STATE explore / EPSILON 0.0884116 / ACTION 0 / REWARD -0.01 / Q_MAX  122.10764 / Loss  151.3660888671875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9613935947418213 seconds\n",
      "TIMESTEP 218 / STATE explore / EPSILON 0.0883117 / ACTION 0 / REWARD -0.01 / Q_MAX  133.66322 / Loss  68.71546936035156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9390039443969727 seconds\n",
      "TIMESTEP 219 / STATE explore / EPSILON 0.0882118 / ACTION 0 / REWARD -0.01 / Q_MAX  131.58995 / Loss  196.87013244628906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9899663925170898 seconds\n",
      "TIMESTEP 220 / STATE explore / EPSILON 0.0881119 / ACTION 0 / REWARD -0.01 / Q_MAX  127.48351 / Loss  146.17942810058594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9931259155273438 seconds\n",
      "TIMESTEP 221 / STATE explore / EPSILON 0.088012 / ACTION 0 / REWARD -0.01 / Q_MAX  116.239944 / Loss  170.79942321777344\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.246389627456665 seconds\n",
      "TIMESTEP 222 / STATE explore / EPSILON 0.0879121 / ACTION 0 / REWARD 0.0 / Q_MAX  115.43219 / Loss  63.32445526123047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.18025803565979 seconds\n",
      "TIMESTEP 223 / STATE explore / EPSILON 0.0878122 / ACTION 0 / REWARD -0.01 / Q_MAX  139.88081 / Loss  80.84315490722656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.982546329498291 seconds\n",
      "TIMESTEP 224 / STATE explore / EPSILON 0.0877123 / ACTION 0 / REWARD -0.01 / Q_MAX  120.4896 / Loss  230.68911743164062\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.039658546447754 seconds\n",
      "TIMESTEP 225 / STATE explore / EPSILON 0.0876124 / ACTION 4 / REWARD 0.0 / Q_MAX  139.72765 / Loss  232.3142852783203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9493238925933838 seconds\n",
      "TIMESTEP 226 / STATE explore / EPSILON 0.08751250000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  142.09482 / Loss  149.5785675048828\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9469313621520996 seconds\n",
      "TIMESTEP 227 / STATE explore / EPSILON 0.08741260000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  134.99535 / Loss  189.3678436279297\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9571943283081055 seconds\n",
      "TIMESTEP 228 / STATE explore / EPSILON 0.08731270000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  134.96378 / Loss  84.46479797363281\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2443499565124512 seconds\n",
      "TIMESTEP 229 / STATE explore / EPSILON 0.08721280000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  142.05814 / Loss  171.24810791015625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.150371789932251 seconds\n",
      "TIMESTEP 230 / STATE explore / EPSILON 0.08711290000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  131.78981 / Loss  167.73272705078125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9598782062530518 seconds\n",
      "TIMESTEP 231 / STATE explore / EPSILON 0.08701300000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  144.64891 / Loss  172.40370178222656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9370286464691162 seconds\n",
      "TIMESTEP 232 / STATE explore / EPSILON 0.08691310000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  134.18823 / Loss  177.57992553710938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9493110179901123 seconds\n",
      "TIMESTEP 233 / STATE explore / EPSILON 0.08681320000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  140.4888 / Loss  144.89512634277344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9467606544494629 seconds\n",
      "TIMESTEP 234 / STATE explore / EPSILON 0.08671330000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  162.14192 / Loss  182.52503967285156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9411954879760742 seconds\n",
      "TIMESTEP 235 / STATE explore / EPSILON 0.08661340000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  126.38541 / Loss  166.72122192382812\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9620785713195801 seconds\n",
      "TIMESTEP 236 / STATE explore / EPSILON 0.08651350000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  157.76797 / Loss  202.33609008789062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9655210971832275 seconds\n",
      "TIMESTEP 237 / STATE explore / EPSILON 0.08641360000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  151.64546 / Loss  116.59445190429688\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.252845048904419 seconds\n",
      "TIMESTEP 238 / STATE explore / EPSILON 0.08631370000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  172.96861 / Loss  169.28482055664062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0979089736938477 seconds\n",
      "TIMESTEP 239 / STATE explore / EPSILON 0.08621380000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  152.53409 / Loss  172.6342315673828\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9259870052337646 seconds\n",
      "TIMESTEP 240 / STATE explore / EPSILON 0.08611390000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  164.37904 / Loss  138.88441467285156\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0079498291015625 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 241 / STATE explore / EPSILON 0.08601400000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  186.68533 / Loss  123.30116271972656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9499020576477051 seconds\n",
      "TIMESTEP 242 / STATE explore / EPSILON 0.08591410000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  168.12582 / Loss  241.80572509765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9420602321624756 seconds\n",
      "TIMESTEP 243 / STATE explore / EPSILON 0.08581420000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  165.4071 / Loss  64.79217529296875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9400639533996582 seconds\n",
      "TIMESTEP 244 / STATE explore / EPSILON 0.08571430000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  185.9346 / Loss  73.16072082519531\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2475612163543701 seconds\n",
      "TIMESTEP 245 / STATE explore / EPSILON 0.08561440000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  157.07333 / Loss  133.82911682128906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.4275484085083008 seconds\n",
      "TIMESTEP 246 / STATE explore / EPSILON 0.08551450000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  181.94125 / Loss  282.0411376953125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9563860893249512 seconds\n",
      "TIMESTEP 247 / STATE explore / EPSILON 0.08541460000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  174.55238 / Loss  249.22454833984375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9553861618041992 seconds\n",
      "TIMESTEP 248 / STATE explore / EPSILON 0.08531470000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  173.11157 / Loss  219.7014923095703\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9722788333892822 seconds\n",
      "TIMESTEP 249 / STATE explore / EPSILON 0.08521480000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  208.87508 / Loss  368.9981384277344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9509365558624268 seconds\n",
      "TIMESTEP 250 / STATE explore / EPSILON 0.08511490000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  198.59727 / Loss  366.320068359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9586999416351318 seconds\n",
      "TIMESTEP 251 / STATE explore / EPSILON 0.08501500000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  162.20505 / Loss  273.95697021484375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9516024589538574 seconds\n",
      "TIMESTEP 252 / STATE explore / EPSILON 0.08491510000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  189.37756 / Loss  189.45086669921875\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2362487316131592 seconds\n",
      "TIMESTEP 253 / STATE explore / EPSILON 0.08481520000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  203.50426 / Loss  320.9661865234375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.134641170501709 seconds\n",
      "TIMESTEP 254 / STATE explore / EPSILON 0.08471530000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  198.71323 / Loss  376.0338134765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0210363864898682 seconds\n",
      "TIMESTEP 255 / STATE explore / EPSILON 0.08461540000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  202.19713 / Loss  206.095458984375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9418842792510986 seconds\n",
      "TIMESTEP 256 / STATE explore / EPSILON 0.08451550000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  192.61984 / Loss  428.6667785644531\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0117666721343994 seconds\n",
      "TIMESTEP 257 / STATE explore / EPSILON 0.08441560000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  186.07304 / Loss  121.26826477050781\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9797999858856201 seconds\n",
      "TIMESTEP 258 / STATE explore / EPSILON 0.08431570000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  170.62726 / Loss  245.14260864257812\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0145318508148193 seconds\n",
      "TIMESTEP 259 / STATE explore / EPSILON 0.08421580000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  198.44244 / Loss  338.051025390625\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3331787586212158 seconds\n",
      "TIMESTEP 260 / STATE explore / EPSILON 0.08411590000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  223.02776 / Loss  321.3349609375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0134751796722412 seconds\n",
      "TIMESTEP 261 / STATE explore / EPSILON 0.08401600000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  219.98972 / Loss  653.133056640625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9662706851959229 seconds\n",
      "TIMESTEP 262 / STATE explore / EPSILON 0.08391610000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  234.33826 / Loss  821.1753540039062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.956087589263916 seconds\n",
      "TIMESTEP 263 / STATE explore / EPSILON 0.08381620000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  219.58928 / Loss  432.6505126953125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9456393718719482 seconds\n",
      "TIMESTEP 264 / STATE explore / EPSILON 0.08371630000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  211.53009 / Loss  503.03216552734375\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9944336414337158 seconds\n",
      "TIMESTEP 265 / STATE explore / EPSILON 0.08361640000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  187.6969 / Loss  602.2664184570312\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9381287097930908 seconds\n",
      "TIMESTEP 266 / STATE explore / EPSILON 0.08351650000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  204.77737 / Loss  465.5426940917969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9505264759063721 seconds\n",
      "TIMESTEP 267 / STATE explore / EPSILON 0.08341660000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  219.73354 / Loss  258.3373107910156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9986810684204102 seconds\n",
      "TIMESTEP 268 / STATE explore / EPSILON 0.08331670000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  220.0648 / Loss  623.5421142578125\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3165051937103271 seconds\n",
      "TIMESTEP 269 / STATE explore / EPSILON 0.08321680000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  250.15323 / Loss  433.3117370605469\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1830556392669678 seconds\n",
      "TIMESTEP 270 / STATE explore / EPSILON 0.08311690000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  214.81908 / Loss  383.81427001953125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1021549701690674 seconds\n",
      "TIMESTEP 271 / STATE explore / EPSILON 0.08301700000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  216.06012 / Loss  458.6521301269531\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0369093418121338 seconds\n",
      "TIMESTEP 272 / STATE explore / EPSILON 0.08291710000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  207.1701 / Loss  297.9376220703125\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0615153312683105 seconds\n",
      "TIMESTEP 273 / STATE explore / EPSILON 0.08281720000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  228.70714 / Loss  175.3156280517578\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.037294864654541 seconds\n",
      "TIMESTEP 274 / STATE explore / EPSILON 0.08271730000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  189.15071 / Loss  158.7855682373047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9786229133605957 seconds\n",
      "TIMESTEP 275 / STATE explore / EPSILON 0.08261740000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  214.19972 / Loss  145.96116638183594\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.305753231048584 seconds\n",
      "TIMESTEP 276 / STATE explore / EPSILON 0.08251750000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  216.273 / Loss  208.962890625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1622157096862793 seconds\n",
      "TIMESTEP 277 / STATE explore / EPSILON 0.08241760000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  214.25581 / Loss  284.0649719238281\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9967677593231201 seconds\n",
      "TIMESTEP 278 / STATE explore / EPSILON 0.08231770000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  196.34064 / Loss  230.7122802734375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9979443550109863 seconds\n",
      "TIMESTEP 279 / STATE explore / EPSILON 0.08221780000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  172.71066 / Loss  228.97216796875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0208234786987305 seconds\n",
      "TIMESTEP 280 / STATE explore / EPSILON 0.08211790000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  158.4377 / Loss  242.9803466796875\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9999854564666748 seconds\n",
      "TIMESTEP 281 / STATE explore / EPSILON 0.08201800000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  223.95988 / Loss  265.766845703125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0435075759887695 seconds\n",
      "TIMESTEP 282 / STATE explore / EPSILON 0.08191810000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  200.42126 / Loss  71.06578826904297\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7116405963897705 seconds\n",
      "TIMESTEP 283 / STATE explore / EPSILON 0.08181820000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  206.97765 / Loss  67.75788879394531\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6810173988342285 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 284 / STATE explore / EPSILON 0.08171830000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  178.83427 / Loss  127.01671600341797\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9889321327209473 seconds\n",
      "TIMESTEP 285 / STATE explore / EPSILON 0.08161840000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  163.80676 / Loss  253.41220092773438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0457007884979248 seconds\n",
      "TIMESTEP 286 / STATE explore / EPSILON 0.08151850000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  203.95026 / Loss  194.0777130126953\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6833844184875488 seconds\n",
      "TIMESTEP 287 / STATE explore / EPSILON 0.08141860000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  174.16632 / Loss  215.4600372314453\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6850347518920898 seconds\n",
      "TIMESTEP 288 / STATE explore / EPSILON 0.08131870000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  158.93517 / Loss  73.84422302246094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6789536476135254 seconds\n",
      "TIMESTEP 289 / STATE explore / EPSILON 0.08121880000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  131.83998 / Loss  129.46548461914062\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7204995155334473 seconds\n",
      "TIMESTEP 290 / STATE explore / EPSILON 0.08111890000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  155.67609 / Loss  55.864105224609375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6816375255584717 seconds\n",
      "TIMESTEP 291 / STATE explore / EPSILON 0.08101900000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  111.13957 / Loss  42.52918243408203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6836099624633789 seconds\n",
      "TIMESTEP 292 / STATE explore / EPSILON 0.08091910000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  126.77156 / Loss  45.21027374267578\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7169327735900879 seconds\n",
      "TIMESTEP 293 / STATE explore / EPSILON 0.08081920000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  129.46776 / Loss  87.92854309082031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7256264686584473 seconds\n",
      "TIMESTEP 294 / STATE explore / EPSILON 0.08071930000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  100.42614 / Loss  81.55380249023438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7235934734344482 seconds\n",
      "TIMESTEP 295 / STATE explore / EPSILON 0.08061940000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.98338 / Loss  74.83293151855469\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6980304718017578 seconds\n",
      "TIMESTEP 296 / STATE explore / EPSILON 0.08051950000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  132.82706 / Loss  31.806480407714844\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0270061492919922 seconds\n",
      "TIMESTEP 297 / STATE explore / EPSILON 0.08041960000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  92.75146 / Loss  58.884178161621094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0425121784210205 seconds\n",
      "TIMESTEP 298 / STATE explore / EPSILON 0.08031970000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  113.0723 / Loss  127.00828552246094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6961002349853516 seconds\n",
      "TIMESTEP 299 / STATE explore / EPSILON 0.08021980000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  102.13655 / Loss  50.068878173828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6980352401733398 seconds\n",
      "TIMESTEP 300 / STATE explore / EPSILON 0.08011990000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  97.70058 / Loss  53.739044189453125\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9684510231018066 seconds\n",
      "TIMESTEP 301 / STATE explore / EPSILON 0.08002000000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  95.039215 / Loss  120.48207092285156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.982863187789917 seconds\n",
      "TIMESTEP 302 / STATE explore / EPSILON 0.07992010000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.52168 / Loss  123.00775146484375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6802408695220947 seconds\n",
      "TIMESTEP 303 / STATE explore / EPSILON 0.07982020000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  151.44798 / Loss  62.22196960449219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6889739036560059 seconds\n",
      "TIMESTEP 304 / STATE explore / EPSILON 0.07972030000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  100.32702 / Loss  61.19792938232422\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7677061557769775 seconds\n",
      "TIMESTEP 305 / STATE explore / EPSILON 0.07962040000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  73.6003 / Loss  63.584590911865234\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.727755069732666 seconds\n",
      "TIMESTEP 306 / STATE explore / EPSILON 0.07952050000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.22087 / Loss  42.59062576293945\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7467360496520996 seconds\n",
      "TIMESTEP 307 / STATE explore / EPSILON 0.07942060000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.927704 / Loss  52.89946365356445\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9057574272155762 seconds\n",
      "TIMESTEP 308 / STATE explore / EPSILON 0.07932070000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.998764 / Loss  53.425010681152344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6832315921783447 seconds\n",
      "TIMESTEP 309 / STATE explore / EPSILON 0.07922080000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  60.03057 / Loss  62.364410400390625\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9749553203582764 seconds\n",
      "TIMESTEP 310 / STATE explore / EPSILON 0.07912090000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  77.417175 / Loss  57.99791717529297\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0102522373199463 seconds\n",
      "TIMESTEP 311 / STATE explore / EPSILON 0.07902100000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.09157 / Loss  49.66912078857422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6826591491699219 seconds\n",
      "TIMESTEP 312 / STATE explore / EPSILON 0.07892110000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  84.14918 / Loss  54.58488845825195\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7137038707733154 seconds\n",
      "TIMESTEP 313 / STATE explore / EPSILON 0.07882120000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  83.240326 / Loss  33.07621765136719\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7056107521057129 seconds\n",
      "TIMESTEP 314 / STATE explore / EPSILON 0.07872130000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.07053 / Loss  52.875518798828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7098345756530762 seconds\n",
      "TIMESTEP 315 / STATE explore / EPSILON 0.07862140000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.98572 / Loss  37.92768859863281\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6857218742370605 seconds\n",
      "TIMESTEP 316 / STATE explore / EPSILON 0.07852150000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  53.129498 / Loss  39.072242736816406\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7075159549713135 seconds\n",
      "TIMESTEP 317 / STATE explore / EPSILON 0.07842160000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  60.68527 / Loss  50.87374496459961\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6911628246307373 seconds\n",
      "TIMESTEP 318 / STATE explore / EPSILON 0.07832170000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.70488 / Loss  34.36552429199219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6792659759521484 seconds\n",
      "TIMESTEP 319 / STATE explore / EPSILON 0.07822180000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  62.292847 / Loss  34.108192443847656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6880087852478027 seconds\n",
      "TIMESTEP 320 / STATE explore / EPSILON 0.07812190000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  64.37115 / Loss  37.1772575378418\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6963176727294922 seconds\n",
      "TIMESTEP 321 / STATE explore / EPSILON 0.07802200000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  56.041893 / Loss  45.711448669433594\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9911057949066162 seconds\n",
      "TIMESTEP 322 / STATE explore / EPSILON 0.07792210000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  77.044624 / Loss  43.65324020385742\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.044844388961792 seconds\n",
      "TIMESTEP 323 / STATE explore / EPSILON 0.07782220000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  107.64901 / Loss  32.97053527832031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6844792366027832 seconds\n",
      "TIMESTEP 324 / STATE explore / EPSILON 0.07772230000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  68.828354 / Loss  44.18583679199219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7002041339874268 seconds\n",
      "TIMESTEP 325 / STATE explore / EPSILON 0.07762240000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  113.00684 / Loss  28.17696189880371\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6991286277770996 seconds\n",
      "TIMESTEP 326 / STATE explore / EPSILON 0.07752250000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  67.644066 / Loss  33.01355743408203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6792497634887695 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 327 / STATE explore / EPSILON 0.07742260000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  68.16683 / Loss  33.390541076660156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6823420524597168 seconds\n",
      "TIMESTEP 328 / STATE explore / EPSILON 0.07732270000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.003654 / Loss  32.26101303100586\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7192764282226562 seconds\n",
      "TIMESTEP 329 / STATE explore / EPSILON 0.07722280000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  65.55631 / Loss  33.0869140625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7184231281280518 seconds\n",
      "TIMESTEP 330 / STATE explore / EPSILON 0.07712290000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  73.31682 / Loss  23.71188735961914\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6996369361877441 seconds\n",
      "TIMESTEP 331 / STATE explore / EPSILON 0.07702300000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  64.16939 / Loss  31.07718276977539\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6957864761352539 seconds\n",
      "TIMESTEP 332 / STATE explore / EPSILON 0.07692310000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.17488 / Loss  32.81999206542969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6808712482452393 seconds\n",
      "TIMESTEP 333 / STATE explore / EPSILON 0.07682320000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  72.753105 / Loss  33.9194221496582\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9895057678222656 seconds\n",
      "TIMESTEP 334 / STATE explore / EPSILON 0.07672330000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  81.39956 / Loss  47.64201736450195\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8981478214263916 seconds\n",
      "TIMESTEP 335 / STATE explore / EPSILON 0.07662340000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.112 / Loss  42.09718322753906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8924195766448975 seconds\n",
      "TIMESTEP 336 / STATE explore / EPSILON 0.07652350000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.909424 / Loss  30.112606048583984\n",
      "[1. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9509115219116211 seconds\n",
      "TIMESTEP 337 / STATE explore / EPSILON 0.07642360000000001 / ACTION 1 / REWARD 0.0 / Q_MAX  84.941124 / Loss  49.40678787231445\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9049267768859863 seconds\n",
      "TIMESTEP 338 / STATE explore / EPSILON 0.07632370000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.20677 / Loss  31.801868438720703\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.917999267578125 seconds\n",
      "TIMESTEP 339 / STATE explore / EPSILON 0.07622380000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  66.89482 / Loss  49.19321823120117\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9311668872833252 seconds\n",
      "TIMESTEP 340 / STATE explore / EPSILON 0.07612390000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  58.64904 / Loss  49.51561737060547\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.935297966003418 seconds\n",
      "TIMESTEP 341 / STATE explore / EPSILON 0.07602400000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.88608 / Loss  47.093894958496094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8091444969177246 seconds\n",
      "TIMESTEP 342 / STATE explore / EPSILON 0.07592410000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.49136 / Loss  28.011493682861328\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7757358551025391 seconds\n",
      "TIMESTEP 343 / STATE explore / EPSILON 0.07582420000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.25804 / Loss  53.87852478027344\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1232359409332275 seconds\n",
      "TIMESTEP 344 / STATE explore / EPSILON 0.07572430000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  54.112453 / Loss  61.93102264404297\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9373855590820312 seconds\n",
      "TIMESTEP 345 / STATE explore / EPSILON 0.07562440000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  81.1897 / Loss  65.29613494873047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.791571855545044 seconds\n",
      "TIMESTEP 346 / STATE explore / EPSILON 0.07552450000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  101.62379 / Loss  40.359642028808594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.792837381362915 seconds\n",
      "TIMESTEP 347 / STATE explore / EPSILON 0.07542460000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.78107 / Loss  41.90583801269531\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7490799427032471 seconds\n",
      "TIMESTEP 348 / STATE explore / EPSILON 0.07532470000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  63.961826 / Loss  72.1791763305664\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7566781044006348 seconds\n",
      "TIMESTEP 349 / STATE explore / EPSILON 0.07522480000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  100.735176 / Loss  21.342754364013672\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2928693294525146 seconds\n",
      "TIMESTEP 350 / STATE explore / EPSILON 0.07512490000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  87.83225 / Loss  77.41051483154297\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1335422992706299 seconds\n",
      "TIMESTEP 351 / STATE explore / EPSILON 0.07502500000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.17877 / Loss  83.86174774169922\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.153230905532837 seconds\n",
      "TIMESTEP 352 / STATE explore / EPSILON 0.07492510000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.95691 / Loss  70.85520935058594\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.1583738327026367 seconds\n",
      "TIMESTEP 353 / STATE explore / EPSILON 0.07482520000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  82.64544 / Loss  42.850677490234375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9095377922058105 seconds\n",
      "TIMESTEP 354 / STATE explore / EPSILON 0.07472530000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.94865 / Loss  30.677310943603516\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.000303030014038 seconds\n",
      "TIMESTEP 355 / STATE explore / EPSILON 0.07462540000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.55073 / Loss  78.51957702636719\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.963655948638916 seconds\n",
      "TIMESTEP 356 / STATE explore / EPSILON 0.07452550000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.0688 / Loss  17.96575164794922\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2182252407073975 seconds\n",
      "TIMESTEP 357 / STATE explore / EPSILON 0.07442560000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  78.60967 / Loss  20.88143539428711\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0756685733795166 seconds\n",
      "TIMESTEP 358 / STATE explore / EPSILON 0.07432570000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.55048 / Loss  94.765380859375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7012181282043457 seconds\n",
      "TIMESTEP 359 / STATE explore / EPSILON 0.07422580000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.823296 / Loss  92.32467651367188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6836051940917969 seconds\n",
      "TIMESTEP 360 / STATE explore / EPSILON 0.07412590000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  112.52604 / Loss  43.54100036621094\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7324998378753662 seconds\n",
      "TIMESTEP 361 / STATE explore / EPSILON 0.07402600000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  101.85955 / Loss  35.60018539428711\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7341930866241455 seconds\n",
      "TIMESTEP 362 / STATE explore / EPSILON 0.07392610000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  100.9655 / Loss  77.22771453857422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6976792812347412 seconds\n",
      "TIMESTEP 363 / STATE explore / EPSILON 0.07382620000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.58342 / Loss  88.43278503417969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7737431526184082 seconds\n",
      "TIMESTEP 364 / STATE explore / EPSILON 0.07372630000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  90.56462 / Loss  23.28469467163086\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1642310619354248 seconds\n",
      "TIMESTEP 365 / STATE explore / EPSILON 0.07362640000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  82.983505 / Loss  122.03582000732422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9694712162017822 seconds\n",
      "TIMESTEP 366 / STATE explore / EPSILON 0.07352650000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  96.83912 / Loss  81.60188293457031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8474953174591064 seconds\n",
      "TIMESTEP 367 / STATE explore / EPSILON 0.07342660000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  108.54361 / Loss  84.77557373046875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8551449775695801 seconds\n",
      "TIMESTEP 368 / STATE explore / EPSILON 0.07332670000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.928375 / Loss  97.58296203613281\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.8882884979248047 seconds\n",
      "TIMESTEP 369 / STATE explore / EPSILON 0.07322680000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  83.805466 / Loss  79.00907897949219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8522968292236328 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 370 / STATE explore / EPSILON 0.07312690000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  94.2781 / Loss  79.50166320800781\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8667151927947998 seconds\n",
      "TIMESTEP 371 / STATE explore / EPSILON 0.07302700000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.43497 / Loss  82.02300262451172\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8642010688781738 seconds\n",
      "TIMESTEP 372 / STATE explore / EPSILON 0.07292710000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  99.49108 / Loss  65.64602661132812\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1467440128326416 seconds\n",
      "TIMESTEP 373 / STATE explore / EPSILON 0.07282720000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  83.480705 / Loss  61.03225326538086\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1331067085266113 seconds\n",
      "TIMESTEP 374 / STATE explore / EPSILON 0.07272730000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  111.74371 / Loss  98.21295166015625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6952464580535889 seconds\n",
      "TIMESTEP 375 / STATE explore / EPSILON 0.07262740000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  138.98245 / Loss  51.70751190185547\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6668610572814941 seconds\n",
      "TIMESTEP 376 / STATE explore / EPSILON 0.07252750000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  103.55103 / Loss  87.09541320800781\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7022814750671387 seconds\n",
      "TIMESTEP 377 / STATE explore / EPSILON 0.07242760000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  117.539795 / Loss  84.78369140625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7167384624481201 seconds\n",
      "TIMESTEP 378 / STATE explore / EPSILON 0.07232770000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  132.94008 / Loss  115.56663513183594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8239712715148926 seconds\n",
      "TIMESTEP 379 / STATE explore / EPSILON 0.07222780000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  112.66626 / Loss  85.39925384521484\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.850205659866333 seconds\n",
      "TIMESTEP 380 / STATE explore / EPSILON 0.07212790000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  137.36983 / Loss  146.28805541992188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8444428443908691 seconds\n",
      "TIMESTEP 381 / STATE explore / EPSILON 0.07202800000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  132.88837 / Loss  107.79927825927734\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8526573181152344 seconds\n",
      "TIMESTEP 382 / STATE explore / EPSILON 0.07192810000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  121.87122 / Loss  174.09823608398438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8504295349121094 seconds\n",
      "TIMESTEP 383 / STATE explore / EPSILON 0.07182820000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  142.53004 / Loss  123.37751007080078\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1284456253051758 seconds\n",
      "TIMESTEP 384 / STATE explore / EPSILON 0.07172830000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  147.58434 / Loss  97.51997375488281\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.9749188423156738 seconds\n",
      "TIMESTEP 385 / STATE explore / EPSILON 0.07162840000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  137.3289 / Loss  159.08349609375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7393388748168945 seconds\n",
      "TIMESTEP 386 / STATE explore / EPSILON 0.07152850000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  119.530914 / Loss  172.6636505126953\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8031504154205322 seconds\n",
      "TIMESTEP 387 / STATE explore / EPSILON 0.07142860000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  147.10394 / Loss  122.94052124023438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9170846939086914 seconds\n",
      "TIMESTEP 388 / STATE explore / EPSILON 0.07132870000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  102.698715 / Loss  165.8753204345703\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2424108982086182 seconds\n",
      "TIMESTEP 389 / STATE explore / EPSILON 0.07122880000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  102.28852 / Loss  139.60647583007812\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9956073760986328 seconds\n",
      "TIMESTEP 390 / STATE explore / EPSILON 0.07112890000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  102.31579 / Loss  121.84712219238281\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0639498233795166 seconds\n",
      "TIMESTEP 391 / STATE explore / EPSILON 0.07102900000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  121.166245 / Loss  100.96842956542969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0811216831207275 seconds\n",
      "TIMESTEP 392 / STATE explore / EPSILON 0.07092910000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  137.20001 / Loss  131.00196838378906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0937325954437256 seconds\n",
      "TIMESTEP 393 / STATE explore / EPSILON 0.07082920000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.22406 / Loss  63.31541061401367\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8372714519500732 seconds\n",
      "TIMESTEP 394 / STATE explore / EPSILON 0.07072930000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  127.3651 / Loss  113.5682144165039\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0235364437103271 seconds\n",
      "TIMESTEP 395 / STATE explore / EPSILON 0.07062940000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.09448 / Loss  181.30349731445312\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1104586124420166 seconds\n",
      "TIMESTEP 396 / STATE explore / EPSILON 0.07052950000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  124.3009 / Loss  48.21506881713867\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9961733818054199 seconds\n",
      "TIMESTEP 397 / STATE explore / EPSILON 0.07042960000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  118.54491 / Loss  128.22369384765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1391870975494385 seconds\n",
      "TIMESTEP 398 / STATE explore / EPSILON 0.07032970000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  108.22782 / Loss  143.0101318359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0208661556243896 seconds\n",
      "TIMESTEP 399 / STATE explore / EPSILON 0.07022980000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  106.809814 / Loss  135.86024475097656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.700796365737915 seconds\n",
      "TIMESTEP 400 / STATE explore / EPSILON 0.07012990000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  107.09987 / Loss  50.38734817504883\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7323896884918213 seconds\n",
      "TIMESTEP 401 / STATE explore / EPSILON 0.07003000000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  94.06519 / Loss  105.01774597167969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7487270832061768 seconds\n",
      "TIMESTEP 402 / STATE explore / EPSILON 0.06993010000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.40257 / Loss  83.2245101928711\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.759758472442627 seconds\n",
      "TIMESTEP 403 / STATE explore / EPSILON 0.06983020000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  114.82185 / Loss  82.30729675292969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.846776008605957 seconds\n",
      "TIMESTEP 404 / STATE explore / EPSILON 0.06973030000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  128.12311 / Loss  90.26530456542969\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1550378799438477 seconds\n",
      "TIMESTEP 405 / STATE explore / EPSILON 0.06963040000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  132.60571 / Loss  45.3995361328125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0129849910736084 seconds\n",
      "TIMESTEP 406 / STATE explore / EPSILON 0.06953050000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  142.41399 / Loss  20.624074935913086\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.828016996383667 seconds\n",
      "TIMESTEP 407 / STATE explore / EPSILON 0.06943060000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  149.18687 / Loss  105.28277587890625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7173700332641602 seconds\n",
      "TIMESTEP 408 / STATE explore / EPSILON 0.06933070000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  127.82764 / Loss  116.21598815917969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6965444087982178 seconds\n",
      "TIMESTEP 409 / STATE explore / EPSILON 0.06923080000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  113.23732 / Loss  159.78878784179688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6990561485290527 seconds\n",
      "TIMESTEP 410 / STATE explore / EPSILON 0.06913090000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  146.35432 / Loss  152.00042724609375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7179958820343018 seconds\n",
      "TIMESTEP 411 / STATE explore / EPSILON 0.06903100000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  128.83154 / Loss  93.07963562011719\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6856586933135986 seconds\n",
      "TIMESTEP 412 / STATE explore / EPSILON 0.06893110000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  144.67667 / Loss  65.16590881347656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8017504215240479 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 413 / STATE explore / EPSILON 0.06883120000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  111.51411 / Loss  43.735748291015625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8537182807922363 seconds\n",
      "TIMESTEP 414 / STATE explore / EPSILON 0.06873130000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  128.96568 / Loss  41.0289421081543\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8479678630828857 seconds\n",
      "TIMESTEP 415 / STATE explore / EPSILON 0.06863140000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  139.65036 / Loss  89.224609375\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1447439193725586 seconds\n",
      "TIMESTEP 416 / STATE explore / EPSILON 0.06853150000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  129.18048 / Loss  87.52239990234375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1333625316619873 seconds\n",
      "TIMESTEP 417 / STATE explore / EPSILON 0.06843160000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  145.21846 / Loss  83.13749694824219\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8022580146789551 seconds\n",
      "TIMESTEP 418 / STATE explore / EPSILON 0.06833170000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  169.53761 / Loss  81.10594177246094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8095908164978027 seconds\n",
      "TIMESTEP 419 / STATE explore / EPSILON 0.06823180000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  142.95326 / Loss  66.44499206542969\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7092556953430176 seconds\n",
      "TIMESTEP 420 / STATE explore / EPSILON 0.06813190000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  143.22456 / Loss  43.549217224121094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8171722888946533 seconds\n",
      "TIMESTEP 421 / STATE explore / EPSILON 0.06803200000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  157.34572 / Loss  73.05116271972656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8452699184417725 seconds\n",
      "TIMESTEP 422 / STATE explore / EPSILON 0.06793210000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  147.09598 / Loss  61.55023956298828\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8560571670532227 seconds\n",
      "TIMESTEP 423 / STATE explore / EPSILON 0.06783220000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  140.03719 / Loss  51.381561279296875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8501973152160645 seconds\n",
      "TIMESTEP 424 / STATE explore / EPSILON 0.06773230000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  150.87561 / Loss  39.26716995239258\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.8932356834411621 seconds\n",
      "TIMESTEP 425 / STATE explore / EPSILON 0.06763240000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  135.35786 / Loss  34.535064697265625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8663339614868164 seconds\n",
      "TIMESTEP 426 / STATE explore / EPSILON 0.06753250000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  121.6104 / Loss  66.7806396484375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6960117816925049 seconds\n",
      "TIMESTEP 427 / STATE explore / EPSILON 0.06743260000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  153.50812 / Loss  39.74706268310547\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7177419662475586 seconds\n",
      "TIMESTEP 428 / STATE explore / EPSILON 0.06733270000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  181.00005 / Loss  256.0140686035156\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.9904403686523438 seconds\n",
      "TIMESTEP 429 / STATE explore / EPSILON 0.06723280000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  174.44151 / Loss  368.91070556640625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0266821384429932 seconds\n",
      "TIMESTEP 430 / STATE explore / EPSILON 0.06713290000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  101.172325 / Loss  42.626502990722656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6944994926452637 seconds\n",
      "TIMESTEP 431 / STATE explore / EPSILON 0.06703300000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  160.30458 / Loss  148.23121643066406\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6851074695587158 seconds\n",
      "TIMESTEP 432 / STATE explore / EPSILON 0.06693310000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  152.16869 / Loss  186.05230712890625\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.7324650287628174 seconds\n",
      "TIMESTEP 433 / STATE explore / EPSILON 0.06683320000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  111.79689 / Loss  233.51828002929688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.762138843536377 seconds\n",
      "TIMESTEP 434 / STATE explore / EPSILON 0.06673330000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  156.033 / Loss  208.36398315429688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.848430871963501 seconds\n",
      "TIMESTEP 435 / STATE explore / EPSILON 0.06663340000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  114.55768 / Loss  181.59664916992188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8340754508972168 seconds\n",
      "TIMESTEP 436 / STATE explore / EPSILON 0.06653350000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  126.664696 / Loss  112.14585876464844\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1601543426513672 seconds\n",
      "TIMESTEP 437 / STATE explore / EPSILON 0.06643360000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  97.68165 / Loss  118.94012451171875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0740959644317627 seconds\n",
      "TIMESTEP 438 / STATE explore / EPSILON 0.06633370000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  153.40186 / Loss  134.86114501953125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6989765167236328 seconds\n",
      "TIMESTEP 439 / STATE explore / EPSILON 0.06623380000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  150.1941 / Loss  113.64292907714844\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7064836025238037 seconds\n",
      "TIMESTEP 440 / STATE explore / EPSILON 0.06613390000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.1291 / Loss  174.5296630859375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6944160461425781 seconds\n",
      "TIMESTEP 441 / STATE explore / EPSILON 0.06603400000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  130.62378 / Loss  141.25714111328125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6886153221130371 seconds\n",
      "TIMESTEP 442 / STATE explore / EPSILON 0.06593410000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  127.85785 / Loss  105.07366180419922\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6942534446716309 seconds\n",
      "TIMESTEP 443 / STATE explore / EPSILON 0.06583420000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  67.891235 / Loss  124.69125366210938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8294570446014404 seconds\n",
      "TIMESTEP 444 / STATE explore / EPSILON 0.06573430000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  90.439285 / Loss  42.98382568359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8818280696868896 seconds\n",
      "TIMESTEP 445 / STATE explore / EPSILON 0.06563440000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  99.504776 / Loss  111.6978759765625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8475544452667236 seconds\n",
      "TIMESTEP 446 / STATE explore / EPSILON 0.06553450000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  100.73684 / Loss  77.69185638427734\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8618514537811279 seconds\n",
      "TIMESTEP 447 / STATE explore / EPSILON 0.06543460000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  91.16025 / Loss  70.1387710571289\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1494379043579102 seconds\n",
      "TIMESTEP 448 / STATE explore / EPSILON 0.06533470000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  85.625885 / Loss  80.97297668457031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.4679768085479736 seconds\n",
      "TIMESTEP 449 / STATE explore / EPSILON 0.06523480000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  67.776855 / Loss  75.55715942382812\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7246878147125244 seconds\n",
      "TIMESTEP 450 / STATE explore / EPSILON 0.06513490000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.8627 / Loss  56.86351776123047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.687962532043457 seconds\n",
      "TIMESTEP 451 / STATE explore / EPSILON 0.06503500000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  69.7576 / Loss  54.205169677734375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7309904098510742 seconds\n",
      "TIMESTEP 452 / STATE explore / EPSILON 0.06493510000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.87623 / Loss  79.95369720458984\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7338612079620361 seconds\n",
      "TIMESTEP 453 / STATE explore / EPSILON 0.06483520000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.0528 / Loss  25.82908821105957\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8050885200500488 seconds\n",
      "TIMESTEP 454 / STATE explore / EPSILON 0.06473530000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  60.68237 / Loss  60.72960662841797\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8936326503753662 seconds\n",
      "TIMESTEP 455 / STATE explore / EPSILON 0.06463540000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  69.311485 / Loss  73.30744934082031\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8657779693603516 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 456 / STATE explore / EPSILON 0.06453550000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  120.56356 / Loss  43.796302795410156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8919847011566162 seconds\n",
      "TIMESTEP 457 / STATE explore / EPSILON 0.06443560000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.396065 / Loss  70.43374633789062\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.132598876953125 seconds\n",
      "TIMESTEP 458 / STATE explore / EPSILON 0.06433570000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  97.17613 / Loss  45.109779357910156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.011171579360962 seconds\n",
      "TIMESTEP 459 / STATE explore / EPSILON 0.06423580000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.61705 / Loss  71.28620147705078\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.695915699005127 seconds\n",
      "TIMESTEP 460 / STATE explore / EPSILON 0.06413590000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.880554 / Loss  68.87821197509766\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7532808780670166 seconds\n",
      "TIMESTEP 461 / STATE explore / EPSILON 0.06403600000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.02627 / Loss  76.9223403930664\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7174301147460938 seconds\n",
      "TIMESTEP 462 / STATE explore / EPSILON 0.06393610000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  111.378784 / Loss  62.91664123535156\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6826093196868896 seconds\n",
      "TIMESTEP 463 / STATE explore / EPSILON 0.06383620000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  89.7453 / Loss  61.76648712158203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6962683200836182 seconds\n",
      "TIMESTEP 464 / STATE explore / EPSILON 0.06373630000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  84.58765 / Loss  32.74951171875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8534591197967529 seconds\n",
      "TIMESTEP 465 / STATE explore / EPSILON 0.06363640000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.84449 / Loss  49.157283782958984\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8523721694946289 seconds\n",
      "TIMESTEP 466 / STATE explore / EPSILON 0.06353650000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  113.09018 / Loss  56.84880828857422\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8482539653778076 seconds\n",
      "TIMESTEP 467 / STATE explore / EPSILON 0.06343660000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.619316 / Loss  27.73856544494629\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8564419746398926 seconds\n",
      "TIMESTEP 468 / STATE explore / EPSILON 0.06333670000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.14895 / Loss  19.64519691467285\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1395907402038574 seconds\n",
      "TIMESTEP 469 / STATE explore / EPSILON 0.06323680000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  75.953186 / Loss  21.351699829101562\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9573523998260498 seconds\n",
      "TIMESTEP 470 / STATE explore / EPSILON 0.06313690000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.10849 / Loss  63.07047653198242\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8499062061309814 seconds\n",
      "TIMESTEP 471 / STATE explore / EPSILON 0.06303700000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  96.24613 / Loss  16.942564010620117\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8484234809875488 seconds\n",
      "TIMESTEP 472 / STATE explore / EPSILON 0.06293710000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.33641 / Loss  20.611209869384766\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8683068752288818 seconds\n",
      "TIMESTEP 473 / STATE explore / EPSILON 0.06283720000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  66.77528 / Loss  47.88315963745117\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8687930107116699 seconds\n",
      "TIMESTEP 474 / STATE explore / EPSILON 0.06273730000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  91.54635 / Loss  45.15748977661133\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8807218074798584 seconds\n",
      "TIMESTEP 475 / STATE explore / EPSILON 0.06263740000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  84.24731 / Loss  50.5224723815918\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8957762718200684 seconds\n",
      "TIMESTEP 476 / STATE explore / EPSILON 0.06253750000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  95.5315 / Loss  44.72949981689453\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8699884414672852 seconds\n",
      "TIMESTEP 477 / STATE explore / EPSILON 0.06243760000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.733284 / Loss  7.7743821144104\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8497259616851807 seconds\n",
      "TIMESTEP 478 / STATE explore / EPSILON 0.06233770000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.08505 / Loss  13.337120056152344\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1552562713623047 seconds\n",
      "TIMESTEP 479 / STATE explore / EPSILON 0.06223780000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  83.70239 / Loss  10.706903457641602\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9586560726165771 seconds\n",
      "TIMESTEP 480 / STATE explore / EPSILON 0.06213790000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  61.735455 / Loss  7.409868240356445\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8122365474700928 seconds\n",
      "TIMESTEP 481 / STATE explore / EPSILON 0.06203800000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.847336 / Loss  10.617033004760742\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7165765762329102 seconds\n",
      "TIMESTEP 482 / STATE explore / EPSILON 0.06193810000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.86744 / Loss  17.148351669311523\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7118790149688721 seconds\n",
      "TIMESTEP 483 / STATE explore / EPSILON 0.06183820000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.594444 / Loss  16.975950241088867\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7552249431610107 seconds\n",
      "TIMESTEP 484 / STATE explore / EPSILON 0.06173830000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.3477 / Loss  13.388042449951172\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6973016262054443 seconds\n",
      "TIMESTEP 485 / STATE explore / EPSILON 0.06163840000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.41363 / Loss  6.5338239669799805\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6979317665100098 seconds\n",
      "TIMESTEP 486 / STATE explore / EPSILON 0.06153850000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  89.476204 / Loss  14.382291793823242\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7204363346099854 seconds\n",
      "TIMESTEP 487 / STATE explore / EPSILON 0.06143860000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.62415 / Loss  8.06467342376709\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7551290988922119 seconds\n",
      "TIMESTEP 488 / STATE explore / EPSILON 0.06133870000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  83.36289 / Loss  17.521427154541016\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9186625480651855 seconds\n",
      "TIMESTEP 489 / STATE explore / EPSILON 0.06123880000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  97.01403 / Loss  12.678065299987793\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1763739585876465 seconds\n",
      "TIMESTEP 490 / STATE explore / EPSILON 0.06113890000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  80.43751 / Loss  16.055789947509766\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9754812717437744 seconds\n",
      "TIMESTEP 491 / STATE explore / EPSILON 0.06103900000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.394615 / Loss  19.040122985839844\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8976707458496094 seconds\n",
      "TIMESTEP 492 / STATE explore / EPSILON 0.06093910000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.19202 / Loss  17.57421112060547\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8639259338378906 seconds\n",
      "TIMESTEP 493 / STATE explore / EPSILON 0.06083920000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  65.75279 / Loss  18.183116912841797\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8508949279785156 seconds\n",
      "TIMESTEP 494 / STATE explore / EPSILON 0.06073930000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.40675 / Loss  14.43193244934082\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8659098148345947 seconds\n",
      "TIMESTEP 495 / STATE explore / EPSILON 0.06063940000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.693436 / Loss  15.529305458068848\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8490898609161377 seconds\n",
      "TIMESTEP 496 / STATE explore / EPSILON 0.06053950000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.244865 / Loss  6.060786724090576\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8784699440002441 seconds\n",
      "TIMESTEP 497 / STATE explore / EPSILON 0.06043960000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  65.49248 / Loss  9.421439170837402\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.98996901512146 seconds\n",
      "TIMESTEP 498 / STATE explore / EPSILON 0.06033970000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.36551 / Loss  9.929912567138672\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8816874027252197 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 499 / STATE explore / EPSILON 0.06023980000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  69.59752 / Loss  8.697717666625977\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1422982215881348 seconds\n",
      "TIMESTEP 500 / STATE explore / EPSILON 0.06013990000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  69.07401 / Loss  4.726713180541992\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1389884948730469 seconds\n",
      "TIMESTEP 501 / STATE explore / EPSILON 0.06004000000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  88.067986 / Loss  5.651064872741699\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7457442283630371 seconds\n",
      "TIMESTEP 502 / STATE explore / EPSILON 0.05994010000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  81.09053 / Loss  7.2344584465026855\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7124614715576172 seconds\n",
      "TIMESTEP 503 / STATE explore / EPSILON 0.05984020000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  68.72039 / Loss  6.013083457946777\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7047016620635986 seconds\n",
      "TIMESTEP 504 / STATE explore / EPSILON 0.05974030000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  81.65368 / Loss  6.940877437591553\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 0.749565839767456 seconds\n",
      "TIMESTEP 505 / STATE explore / EPSILON 0.05964040000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  85.961525 / Loss  4.043783187866211\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8648967742919922 seconds\n",
      "TIMESTEP 506 / STATE explore / EPSILON 0.05954050000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.21601 / Loss  3.924062490463257\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.883040189743042 seconds\n",
      "TIMESTEP 507 / STATE explore / EPSILON 0.05944060000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  89.698006 / Loss  4.085031986236572\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8864943981170654 seconds\n",
      "TIMESTEP 508 / STATE explore / EPSILON 0.05934070000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.45645 / Loss  6.683498859405518\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1422195434570312 seconds\n",
      "TIMESTEP 509 / STATE explore / EPSILON 0.05924080000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  70.08003 / Loss  29.695512771606445\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0421407222747803 seconds\n",
      "TIMESTEP 510 / STATE explore / EPSILON 0.05914090000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.50988 / Loss  12.500531196594238\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7932772636413574 seconds\n",
      "TIMESTEP 511 / STATE explore / EPSILON 0.05904100000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  68.69761 / Loss  25.396703720092773\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7299141883850098 seconds\n",
      "TIMESTEP 512 / STATE explore / EPSILON 0.05894110000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  66.16955 / Loss  29.68202781677246\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.719796895980835 seconds\n",
      "TIMESTEP 513 / STATE explore / EPSILON 0.05884120000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.40158 / Loss  26.246706008911133\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6802353858947754 seconds\n",
      "TIMESTEP 514 / STATE explore / EPSILON 0.05874130000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.929825 / Loss  26.672142028808594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6825094223022461 seconds\n",
      "TIMESTEP 515 / STATE explore / EPSILON 0.05864140000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.87255 / Loss  8.005196571350098\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7044494152069092 seconds\n",
      "TIMESTEP 516 / STATE explore / EPSILON 0.05854150000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.552895 / Loss  20.22922706604004\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.679023027420044 seconds\n",
      "TIMESTEP 517 / STATE explore / EPSILON 0.05844160000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.87455 / Loss  17.28263282775879\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.789046049118042 seconds\n",
      "TIMESTEP 518 / STATE explore / EPSILON 0.05834170000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.19268 / Loss  7.95245885848999\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8376054763793945 seconds\n",
      "TIMESTEP 519 / STATE explore / EPSILON 0.05824180000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.372665 / Loss  11.924217224121094\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.4277594089508057 seconds\n",
      "TIMESTEP 520 / STATE explore / EPSILON 0.05814190000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  82.07922 / Loss  32.25522232055664\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1065170764923096 seconds\n",
      "TIMESTEP 521 / STATE explore / EPSILON 0.05804200000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  65.59879 / Loss  15.355202674865723\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7545516490936279 seconds\n",
      "TIMESTEP 522 / STATE explore / EPSILON 0.05794210000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.990364 / Loss  22.28852653503418\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6845426559448242 seconds\n",
      "TIMESTEP 523 / STATE explore / EPSILON 0.05784220000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  84.19692 / Loss  29.588768005371094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6862185001373291 seconds\n",
      "TIMESTEP 524 / STATE explore / EPSILON 0.05774230000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.865005 / Loss  10.526240348815918\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6836915016174316 seconds\n",
      "TIMESTEP 525 / STATE explore / EPSILON 0.05764240000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  66.85341 / Loss  23.226806640625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6788814067840576 seconds\n",
      "TIMESTEP 526 / STATE explore / EPSILON 0.05754250000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  72.427704 / Loss  23.200267791748047\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6987204551696777 seconds\n",
      "TIMESTEP 527 / STATE explore / EPSILON 0.05744260000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  64.86774 / Loss  19.41558074951172\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7014682292938232 seconds\n",
      "TIMESTEP 528 / STATE explore / EPSILON 0.05734270000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.19 / Loss  15.23390007019043\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7151498794555664 seconds\n",
      "TIMESTEP 529 / STATE explore / EPSILON 0.05724280000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  64.49796 / Loss  9.829143524169922\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7180190086364746 seconds\n",
      "TIMESTEP 530 / STATE explore / EPSILON 0.05714290000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  72.078636 / Loss  10.151227951049805\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7137570381164551 seconds\n",
      "TIMESTEP 531 / STATE explore / EPSILON 0.05704300000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  79.56573 / Loss  14.989371299743652\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.973304033279419 seconds\n",
      "TIMESTEP 532 / STATE explore / EPSILON 0.05694310000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  65.38031 / Loss  20.91351318359375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8143718242645264 seconds\n",
      "TIMESTEP 533 / STATE explore / EPSILON 0.05684320000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  94.22988 / Loss  15.965571403503418\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7292537689208984 seconds\n",
      "TIMESTEP 534 / STATE explore / EPSILON 0.05674330000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  79.363144 / Loss  14.002830505371094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7017595767974854 seconds\n",
      "TIMESTEP 535 / STATE explore / EPSILON 0.05664340000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  72.51047 / Loss  13.336090087890625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7100567817687988 seconds\n",
      "TIMESTEP 536 / STATE explore / EPSILON 0.05654350000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.30118 / Loss  9.597725868225098\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8765206336975098 seconds\n",
      "TIMESTEP 537 / STATE explore / EPSILON 0.05644360000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  66.48116 / Loss  16.704927444458008\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8555121421813965 seconds\n",
      "TIMESTEP 538 / STATE explore / EPSILON 0.05634370000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  81.49237 / Loss  9.085132598876953\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.866710901260376 seconds\n",
      "TIMESTEP 539 / STATE explore / EPSILON 0.05624380000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.935326 / Loss  16.19265365600586\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8222939968109131 seconds\n",
      "TIMESTEP 540 / STATE explore / EPSILON 0.05614390000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.68284 / Loss  13.541054725646973\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6977748870849609 seconds\n",
      "TIMESTEP 541 / STATE explore / EPSILON 0.05604400000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.27639 / Loss  7.324114799499512\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6875724792480469 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 542 / STATE explore / EPSILON 0.05594410000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  73.753075 / Loss  6.95079231262207\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.0210976600646973 seconds\n",
      "TIMESTEP 543 / STATE explore / EPSILON 0.05584420000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  82.69623 / Loss  6.573667049407959\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0026016235351562 seconds\n",
      "TIMESTEP 544 / STATE explore / EPSILON 0.05574430000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.82821 / Loss  11.25205135345459\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.734748125076294 seconds\n",
      "TIMESTEP 545 / STATE explore / EPSILON 0.05564440000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.589966 / Loss  12.779617309570312\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6892907619476318 seconds\n",
      "TIMESTEP 546 / STATE explore / EPSILON 0.05554450000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.87698 / Loss  10.451245307922363\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6824514865875244 seconds\n",
      "TIMESTEP 547 / STATE explore / EPSILON 0.05544460000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.7535 / Loss  9.94111156463623\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6890771389007568 seconds\n",
      "TIMESTEP 548 / STATE explore / EPSILON 0.05534470000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  86.873436 / Loss  10.482248306274414\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6904146671295166 seconds\n",
      "TIMESTEP 549 / STATE explore / EPSILON 0.05524480000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  94.849 / Loss  5.522245407104492\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6870770454406738 seconds\n",
      "TIMESTEP 550 / STATE explore / EPSILON 0.05514490000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  79.10889 / Loss  8.321805953979492\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8338801860809326 seconds\n",
      "TIMESTEP 551 / STATE explore / EPSILON 0.05504500000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.72046 / Loss  8.030294418334961\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.850675106048584 seconds\n",
      "TIMESTEP 552 / STATE explore / EPSILON 0.05494510000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  69.045715 / Loss  6.823624134063721\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.8549582958221436 seconds\n",
      "TIMESTEP 553 / STATE explore / EPSILON 0.05484520000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  95.39919 / Loss  5.450799465179443\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.1464378833770752 seconds\n",
      "TIMESTEP 554 / STATE explore / EPSILON 0.05474530000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  83.30957 / Loss  5.587082862854004\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0080323219299316 seconds\n",
      "TIMESTEP 555 / STATE explore / EPSILON 0.05464540000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  73.11368 / Loss  10.431076049804688\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7039093971252441 seconds\n",
      "TIMESTEP 556 / STATE explore / EPSILON 0.05454550000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  81.87002 / Loss  7.878156661987305\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6842420101165771 seconds\n",
      "TIMESTEP 557 / STATE explore / EPSILON 0.05444560000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.98721 / Loss  9.035650253295898\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6988699436187744 seconds\n",
      "TIMESTEP 558 / STATE explore / EPSILON 0.05434570000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.24813 / Loss  9.874290466308594\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7018003463745117 seconds\n",
      "TIMESTEP 559 / STATE explore / EPSILON 0.05424580000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  86.86295 / Loss  12.836904525756836\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6977400779724121 seconds\n",
      "TIMESTEP 560 / STATE explore / EPSILON 0.05414590000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  75.11311 / Loss  9.191524505615234\n",
      "[1. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.7948591709136963 seconds\n",
      "TIMESTEP 561 / STATE explore / EPSILON 0.05404600000000001 / ACTION 1 / REWARD 0.0 / Q_MAX  85.4748 / Loss  4.448518753051758\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.2542550563812256 seconds\n",
      "TIMESTEP 562 / STATE explore / EPSILON 0.05394610000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  74.227036 / Loss  8.422053337097168\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6827816963195801 seconds\n",
      "TIMESTEP 563 / STATE explore / EPSILON 0.05384620000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.322945 / Loss  9.688522338867188\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6967024803161621 seconds\n",
      "TIMESTEP 564 / STATE explore / EPSILON 0.05374630000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  90.24258 / Loss  8.304305076599121\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.998051643371582 seconds\n",
      "TIMESTEP 565 / STATE explore / EPSILON 0.05364640000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  73.47609 / Loss  6.051839351654053\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0222434997558594 seconds\n",
      "TIMESTEP 566 / STATE explore / EPSILON 0.05354650000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  99.14006 / Loss  7.75769567489624\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7128803730010986 seconds\n",
      "TIMESTEP 567 / STATE explore / EPSILON 0.05344660000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.984825 / Loss  3.2172248363494873\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7009005546569824 seconds\n",
      "TIMESTEP 568 / STATE explore / EPSILON 0.05334670000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  99.34085 / Loss  4.660945415496826\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.6963963508605957 seconds\n",
      "TIMESTEP 569 / STATE explore / EPSILON 0.05324680000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  98.53064 / Loss  5.147263526916504\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.716494083404541 seconds\n",
      "TIMESTEP 570 / STATE explore / EPSILON 0.05314690000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  83.03568 / Loss  3.655202627182007\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.7747068405151367 seconds\n",
      "TIMESTEP 571 / STATE explore / EPSILON 0.05304700000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  82.476906 / Loss  4.157398223876953\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.8396017551422119 seconds\n",
      "TIMESTEP 572 / STATE explore / EPSILON 0.05294710000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  86.710236 / Loss  4.557075023651123\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 0.7695834636688232 seconds\n",
      "TIMESTEP 573 / STATE explore / EPSILON 0.05284720000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  64.449776 / Loss  4.891345024108887\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.021169662475586 seconds\n",
      "TIMESTEP 574 / STATE explore / EPSILON 0.05274730000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  87.44711 / Loss  3.7218661308288574\n",
      "[0. 0. 0. 0.]\n",
      "reward: 1\n",
      "loop took 1.4695053100585938 seconds\n",
      "TIMESTEP 575 / STATE explore / EPSILON 0.05264740000000001 / ACTION 0 / REWARD 1 / Q_MAX  104.42145 / Loss  37.61323547363281\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0834684371948242 seconds\n",
      "TIMESTEP 576 / STATE explore / EPSILON 0.05254750000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  93.46263 / Loss  124.22665405273438\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9297633171081543 seconds\n",
      "TIMESTEP 577 / STATE explore / EPSILON 0.05244760000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.95465 / Loss  123.99176788330078\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9543917179107666 seconds\n",
      "TIMESTEP 578 / STATE explore / EPSILON 0.05234770000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  70.72231 / Loss  118.82510375976562\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1506798267364502 seconds\n",
      "TIMESTEP 579 / STATE explore / EPSILON 0.05224780000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.25971 / Loss  136.828857421875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1589713096618652 seconds\n",
      "TIMESTEP 580 / STATE explore / EPSILON 0.05214790000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.741 / Loss  10.85272216796875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0868759155273438 seconds\n",
      "TIMESTEP 581 / STATE explore / EPSILON 0.05204800000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.260254 / Loss  116.69282531738281\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.036139965057373 seconds\n",
      "TIMESTEP 582 / STATE explore / EPSILON 0.05194810000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  84.06528 / Loss  33.582069396972656\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.3386809825897217 seconds\n",
      "TIMESTEP 583 / STATE explore / EPSILON 0.05184820000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  85.7509 / Loss  135.26840209960938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.2117278575897217 seconds\n",
      "TIMESTEP 584 / STATE explore / EPSILON 0.05174830000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.613205 / Loss  88.07814025878906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.02394437789917 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 585 / STATE explore / EPSILON 0.05164840000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.09392 / Loss  86.25477600097656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1133348941802979 seconds\n",
      "TIMESTEP 586 / STATE explore / EPSILON 0.05154850000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.68775 / Loss  40.1387825012207\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.082216501235962 seconds\n",
      "TIMESTEP 587 / STATE explore / EPSILON 0.05144860000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  83.31858 / Loss  115.73211669921875\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0879371166229248 seconds\n",
      "TIMESTEP 588 / STATE explore / EPSILON 0.05134870000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.707184 / Loss  80.96762084960938\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.152000904083252 seconds\n",
      "TIMESTEP 589 / STATE explore / EPSILON 0.05124880000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.52226 / Loss  70.29627227783203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0360956192016602 seconds\n",
      "TIMESTEP 590 / STATE explore / EPSILON 0.05114890000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.52445 / Loss  84.80587768554688\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.280531406402588 seconds\n",
      "TIMESTEP 591 / STATE explore / EPSILON 0.05104900000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  81.085625 / Loss  51.12873077392578\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.197312831878662 seconds\n",
      "TIMESTEP 592 / STATE explore / EPSILON 0.05094910000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.64284 / Loss  54.273719787597656\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9794051647186279 seconds\n",
      "TIMESTEP 593 / STATE explore / EPSILON 0.05084920000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.97802 / Loss  92.41365051269531\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9564914703369141 seconds\n",
      "TIMESTEP 594 / STATE explore / EPSILON 0.05074930000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  90.05928 / Loss  74.16299438476562\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9515533447265625 seconds\n",
      "TIMESTEP 595 / STATE explore / EPSILON 0.05064940000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  85.66223 / Loss  53.198184967041016\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9474489688873291 seconds\n",
      "TIMESTEP 596 / STATE explore / EPSILON 0.05054950000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  69.75234 / Loss  34.5830192565918\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0634181499481201 seconds\n",
      "TIMESTEP 597 / STATE explore / EPSILON 0.05044960000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  76.32279 / Loss  60.48876190185547\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.930978536605835 seconds\n",
      "TIMESTEP 598 / STATE explore / EPSILON 0.05034970000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  90.12738 / Loss  23.425281524658203\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9523310661315918 seconds\n",
      "TIMESTEP 599 / STATE explore / EPSILON 0.05024980000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  79.77379 / Loss  56.35711669921875\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2507965564727783 seconds\n",
      "TIMESTEP 600 / STATE explore / EPSILON 0.05014990000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  67.472496 / Loss  27.995695114135742\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0503449440002441 seconds\n",
      "TIMESTEP 601 / STATE explore / EPSILON 0.05005000000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  77.067024 / Loss  50.36318588256836\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9461135864257812 seconds\n",
      "TIMESTEP 602 / STATE explore / EPSILON 0.04995010000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  81.468445 / Loss  50.13459014892578\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9910023212432861 seconds\n",
      "TIMESTEP 603 / STATE explore / EPSILON 0.04985020000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.30502 / Loss  22.14345932006836\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0128166675567627 seconds\n",
      "TIMESTEP 604 / STATE explore / EPSILON 0.04975030000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.452965 / Loss  48.842430114746094\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0940759181976318 seconds\n",
      "TIMESTEP 605 / STATE explore / EPSILON 0.04965040000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  78.17318 / Loss  32.13108444213867\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9827761650085449 seconds\n",
      "TIMESTEP 606 / STATE explore / EPSILON 0.04955050000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  67.86257 / Loss  58.488372802734375\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.0009064674377441 seconds\n",
      "TIMESTEP 607 / STATE explore / EPSILON 0.04945060000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  79.21364 / Loss  34.05190658569336\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9340901374816895 seconds\n",
      "TIMESTEP 608 / STATE explore / EPSILON 0.04935070000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  91.29177 / Loss  26.638595581054688\n",
      "[1. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.2807505130767822 seconds\n",
      "TIMESTEP 609 / STATE explore / EPSILON 0.04925080000000001 / ACTION 1 / REWARD 0.0 / Q_MAX  65.493126 / Loss  56.81665802001953\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.1197221279144287 seconds\n",
      "TIMESTEP 610 / STATE explore / EPSILON 0.04915090000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  87.63169 / Loss  47.30022430419922\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9593484401702881 seconds\n",
      "TIMESTEP 611 / STATE explore / EPSILON 0.04905100000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  80.23395 / Loss  68.48200225830078\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9425811767578125 seconds\n",
      "TIMESTEP 612 / STATE explore / EPSILON 0.04895110000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  72.143745 / Loss  45.98057556152344\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9545495510101318 seconds\n",
      "TIMESTEP 613 / STATE explore / EPSILON 0.04885120000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  64.53433 / Loss  39.61607360839844\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9670586585998535 seconds\n",
      "TIMESTEP 614 / STATE explore / EPSILON 0.04875130000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  71.68157 / Loss  29.262203216552734\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9621260166168213 seconds\n",
      "TIMESTEP 615 / STATE explore / EPSILON 0.04865140000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  44.789433 / Loss  30.355253219604492\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9478633403778076 seconds\n",
      "TIMESTEP 616 / STATE explore / EPSILON 0.04855150000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  54.619785 / Loss  17.701541900634766\n",
      "----------Random Action----------\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.0017638206481934 seconds\n",
      "TIMESTEP 617 / STATE explore / EPSILON 0.04845160000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  57.537983 / Loss  11.434834480285645\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9537723064422607 seconds\n",
      "TIMESTEP 618 / STATE explore / EPSILON 0.04835170000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  59.028717 / Loss  36.387847900390625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9412703514099121 seconds\n",
      "TIMESTEP 619 / STATE explore / EPSILON 0.04825180000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  40.457546 / Loss  31.53750991821289\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9542696475982666 seconds\n",
      "TIMESTEP 620 / STATE explore / EPSILON 0.04815190000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  56.896954 / Loss  16.28706169128418\n",
      "[0. 0. 0. 0.]\n",
      "reward: 0.0\n",
      "loop took 1.245406150817871 seconds\n",
      "TIMESTEP 621 / STATE explore / EPSILON 0.04805200000000001 / ACTION 0 / REWARD 0.0 / Q_MAX  56.32881 / Loss  24.632179260253906\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 1.4368572235107422 seconds\n",
      "TIMESTEP 622 / STATE explore / EPSILON 0.04795210000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  38.11918 / Loss  23.96605110168457\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9448418617248535 seconds\n",
      "TIMESTEP 623 / STATE explore / EPSILON 0.04785220000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  46.09246 / Loss  22.424468994140625\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9483251571655273 seconds\n",
      "TIMESTEP 624 / STATE explore / EPSILON 0.04775230000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  57.907227 / Loss  12.66312313079834\n",
      "[0. 0. 0. 1.]\n",
      "reward: 0.0\n",
      "loop took 1.072455644607544 seconds\n",
      "TIMESTEP 625 / STATE explore / EPSILON 0.04765240000000001 / ACTION 4 / REWARD 0.0 / Q_MAX  43.33282 / Loss  24.58662223815918\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.960930347442627 seconds\n",
      "TIMESTEP 626 / STATE explore / EPSILON 0.04755250000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  56.06903 / Loss  21.42706298828125\n",
      "[0. 0. 0. 0.]\n",
      "reward: -0.01\n",
      "loop took 0.9608554840087891 seconds\n",
      "TIMESTEP 627 / STATE explore / EPSILON 0.04745260000000001 / ACTION 0 / REWARD -0.01 / Q_MAX  58.91725 / Loss  11.609722137451172\n",
      "[0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-268-4829a0a02061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplayGame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-266-5098fbf84864>\u001b[0m in \u001b[0;36mplayGame\u001b[1;34m(observe)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mtrainNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-265-0828acd680f4>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[1;34m(model, game_state, observe)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m#run the selected action and observed next state and reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mx_t1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reward: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loop took {} seconds'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlast_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# helpful for measuring frame rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-256-fad30a4b2bef>\u001b[0m in \u001b[0;36mget_state\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#display the image on screen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_crashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;31m#             scores_df.loc[len(loss_df)] = score # log the score when game is over\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-254-ce4eef104250>\u001b[0m in \u001b[0;36mis_crashed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_playing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_crashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_crashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpress_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-253-e92f2c27bc7c>\u001b[0m in \u001b[0;36mget_crashed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#             self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_crashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return Init.instance_.crashed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_playing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"return Init.instance_.playing\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    634\u001b[0m         return self.execute(command, {\n\u001b[0;32m    635\u001b[0m             \u001b[1;34m'script'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             'args': converted_args})['value']\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     70\u001b[0m             return self.request_encode_body(method, url, fields=fields,\n\u001b[0;32m     71\u001b[0m                                             \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                                             **urlopen_kw)\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     def request_encode_url(self, method, url, fields=None, headers=None,\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    601\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chouh\\appdata\\local\\programs\\python\\python37\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "playGame(observe=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "<strong>Loss and Scores :</strong> I trained my model for around 2 million frames for a week. 1st million steps were used for fine tuning the game parameters and fixing bugs.Plotting the last million loss values and all scores record for all the game.  The last million training frames showed improvement in game scores reaching a maximum score of 265 till now. We can observe that loss has stabilized for the last million steps and stays low with minute fluctuations.\n",
    "\n",
    "<strong>Action Distribution</strong>:\n",
    "The density distribution of the actions performed by the model considerd for evaulation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the game training logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1,nrows =2,figsize=(15,15))\n",
    "def show_plots(i):\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[1].set_title('Game Score progress')\n",
    "    loss_df = pd.read_csv(\"./objects/loss_df.csv\").clip(0,50).tail(100000)\n",
    "    scores_df = pd.read_csv(\"./objects/scores_df.csv\").head(190000)\n",
    "    \n",
    "    actions_df = pd.read_csv(\"./objects/actions_df.csv\").tail(100000)\n",
    "    loss_df['loss'] = loss_df['loss'].astype('float') \n",
    "    loss_df.plot(use_index=True,ax=axs[0])\n",
    "    scores_df.plot(ax=axs[1])\n",
    "#     sns.distplot(actions_df,ax=axs[2])\n",
    "    imgg = fig.canvas.draw()\n",
    "\n",
    "animate = animation.FuncAnimation(fig, show_plots, interval=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Comparision between human and AI\n",
    "A gameplay of human was recorded for a score of 500.\n",
    "The plot below shows the distrubtion comparision of actions performed\n",
    "It can be inferred from the comparision that the Model has currently adopted a policy that favours jumps more as compared to doing nothing and which is the main reason the dino can be seen to crash. This behaviour is a sign of noise in the training phase for which more exploration(with higher bias towards 'do nothing' action) training is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploting and comparing AI and human gameplay action distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data_final_working.npy file contains the the keystrokes and gameframes recording for a score of 500\n",
    "supervised_frames = np.load(\"training_data_final_working.npy\")\n",
    "frame = supervised_frames[0][0]\n",
    "action_index = supervised_frames[0][1]\n",
    "#plotting a sample frame from human recorded gameplay\n",
    "plt.imshow(frame)\n",
    "print('Action taken at this frame : Action index = {} i.e. jump'.format(str(action_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_actions = []\n",
    "\n",
    "for frame in supervised_frames:\n",
    "    supervised_actions.append(frame[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=1,nrows =2,figsize=(15,15))\n",
    "sns.distplot(supervised_actions,ax=axs[0])\n",
    "axs[1].set_title('AI gameplay distribution')\n",
    "axs[0].set_title('Human gameplay distribution')\n",
    "actions_df = pd.read_csv(\"./objects/actions_df.csv\")\n",
    "sns.distplot(actions_df,ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "1. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou,\n",
    "Daan Wierstra,  and Martin Riedmiller. Playing Atari with Deep Reinforcement Learning arXiv:1312.5602, 19 Dec 2013\n",
    "2. Kevin Chen, Deep Reinforcement Learning for Flappy Bird.\n",
    "3. Gerald Tesauro. Temporal difference learning and td-gammon. Communications of the ACM, 38(3):5868, 1995.\n",
    "4. Toy example of a deep reinforcement learning model playing a game of catching fruit, https://github.com/bitwise-ben/Fruit\n",
    "5. MNIH, Volodymyr, et al. Human-level control through deep reinforcement learning. Nature, 2015, vol. 518, no 7540, p. 529-533.\n",
    "6. Tambet Matiisen. Demystifying Deep Reinforcement Learning https://ai.intel.com/demystifying-deep-reinforcement-learning/\n",
    "7. Sascha Lange, Thomas Gabel, and Martin Riedmiller. Batch Reinforcement Learning\n",
    "8. Using Deep Q-Network to Learn How To Play Flappy Bird   https://github.com/yenchenlin/DeepLearningFlappyBird\n",
    "9. The image processing modules were inspired from Harrison Sentdex's github which is licensed under the GNU GENERAL PUBLIC LICENSE http://www.gnu.org/licenses/gpl.html<br>\n",
    "10. Coroutine implementation in the code below belongs to Ben Meijering and is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
